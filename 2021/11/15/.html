<h1 id="sickit-learn-for-machine-learning">Sickit-Learn for Machine Learning</h1>

<blockquote>
  <p>In this notebook we will work through an example project end to end using Sickit Learn library.</p>
</blockquote>

<h1 id="about">About</h1>

<p>In this chapter weâ€™ll use the <code class="language-plaintext highlighter-rouge">California Housing Prices dataset</code> from the StatLib repository
This dataset is based on data from the 1990 California census.</p>

<p>This data includes metrics such as the population, median income, and median housing price for each
block group in California. Block groups are the smallest geographical unit for which
the US Census Bureau publishes sample data (a block group typical).</p>

<p>Your model should learn from this data and be able to <code class="language-plaintext highlighter-rouge">predict the median housing price in any district</code>, given all the other metrics.</p>

<p>Goal : Your boss answers that your modelâ€™s output (a prediction of a districtâ€™s median housing
price) will be fed to another Machine Learning system , along
with many other signals. This downstream system will determine whether it is worth
investing in a given area or not. Getting this right is critical, as it directly affects
revenue.</p>

<p>First, you need to frame the problem: is it supervised, unsupervised, or Reinforcement
Learning? Is it a classification task, a regression task, or something else? Should you
use batch learning or online learning techniques?</p>

<p>Letâ€™s see: it is clearly a typical <code class="language-plaintext highlighter-rouge">supervised learning task</code>, since you are given labeled training examples.</p>

<p>It is also a typical <code class="language-plaintext highlighter-rouge">regression task</code>, since you are asked to <code class="language-plaintext highlighter-rouge">predict a value</code>. More specifically, this is a <code class="language-plaintext highlighter-rouge">multiple regression problem</code>, since the system will use <code class="language-plaintext highlighter-rouge">multiple features to make a prediction</code>.</p>

<p>It is also a <code class="language-plaintext highlighter-rouge">univariate regression problem</code>, since we are only trying to predict a <code class="language-plaintext highlighter-rouge">single value</code> for each district.
If we were trying to predict multiple values per district, it would be a multivariate regression problem.</p>

<p>Finally, there is no continuous flow of data coming into the system, there is no particular need to adjust to changing data rapidly, and the data is small enough to fit in memory, so plain <code class="language-plaintext highlighter-rouge">batch learning</code> should do just fine.</p>

<h1 id="select-a-performance-measure">Select a Performance Measure</h1>

<h2 id="performance-measures-for-our-univariate-regression-problem">Performance Measures for our univariate regression problem</h2>

<p>Typical performance measure for regression problems :</p>

<ul>
  <li>
    <p><em>Root Mean Square Error (RMSE)</em>: it gives an idea of how much error the system typically makes in its predictions, <code class="language-plaintext highlighter-rouge">with a higher weight for large errors</code> : Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. <code class="language-plaintext highlighter-rouge">This means the RMSE should be more useful when large errors are particularly undesirable.</code></p>

    <p>RMSE is <code class="language-plaintext highlighter-rouge">sensitive to outliers</code> : If we make a single very bad prediction, taking the square will make the error even worse and it may skew the metric towards <code class="language-plaintext highlighter-rouge">overestimating the modelâ€™s badness</code>.
 Actually, itâ€™s hard to realize if our model is good or not by looking at the absolute values of MSE or MSE : We would probably want to measure <code class="language-plaintext highlighter-rouge">how much our model is better than the constant baseline</code> : A model should at least perform better than the RMSE score constant baseline.</p>

    <p>RMSE has the benefit of penalizing large errors more so can be more appropriate in some cases, for example, if being off by 10 is more than twice as bad as being off by 5. But if being off by 10 is just twice as bad as being off by 5, then MAE is more appropriate.</p>

    <p><img src="attachment:image-3.png" alt="image-3.png" />
         - n is the number of instances in the dataset you are measuring the RMSE on.</p>
  </li>
  <li>
    <p><em>Root Mean Square Log Error (RMSLE)</em>: It is an extension on root Mean Squared Error (RMSE) that is mainly used when <code class="language-plaintext highlighter-rouge">predictions have large deviations</code></p>

    <p>RMSLE is preferable when :</p>
    <ul>
      <li>targets having exponential growth, such as population counts, average sales of a commodity over a span of years etc</li>
      <li>we care about <code class="language-plaintext highlighter-rouge">percentage errors</code> rather than the <code class="language-plaintext highlighter-rouge">absolute value of errors</code> : The reason we use log is because   generally, you care not so much about missing by â‚¬10 but missing by 10%. So if it was â‚¬1000,000 item and you are â‚¬100,000 off or if it was a 10,000 item and you are â‚¬1,000 off â€” we would consider those equivalent scale issues.</li>
      <li>There is a wide range in the target variables and <code class="language-plaintext highlighter-rouge">we donâ€™t want to penalize big differences when both the predicted and the actual are big numbers</code>.</li>
      <li>We want to <code class="language-plaintext highlighter-rouge">penalize under estimates more than over estimates</code>.</li>
      <li>
        <p>Letâ€™s imagine two cases of predictions,</p>

        <p>Case-1: our model makes a prediction of 30 when the actual number is 40
  Case-2: our model makes a prediction of 300 when the actual number is 400</p>

        <p>With RMSE the second result is scored as 10 times more than the first result
  Conversely, with RMSLogE two results are scored the same.
  RMSLogE takes into account just the ratio of change
  Lets have a look at the below example</p>

        <p>Case-3 : Prediction = 600, Actual = 1000 (the absolute difference is 400)</p>

        <p>RMSE = 400,
  RMSLogE = 0.5108</p>

        <p>Case-4 : Prediction = 1400, Actual = 1000 (the absolute difference is 400)</p>

        <p>RMSE = 400,
  RMSLogE = 0.3365</p>

        <p>When the differences are the same between actual and predicted in both cases.
  RMSE treated them equally, however  RMSLogE <code class="language-plaintext highlighter-rouge">penalized the under estimate more than over estimate</code> (under estimated prediction score is higher than over estimated prediction score).
  <code class="language-plaintext highlighter-rouge">Often, penalizing the under estimate more than over estimate is important for prediction of sales and inventory demands</code>.</p>
      </li>
    </ul>
  </li>
</ul>

<p><img src="attachment:image-4.png" alt="image-4.png" /></p>

<ul>
  <li>
    <p><em>Mean Absolute Error (MAE)</em>: also called <code class="language-plaintext highlighter-rouge">the average absolute deviation</code> : 
  MAE measures the average magnitude of the errors in a set of predictions, without considering their direction.</p>

    <p><img src="attachment:image-5.png" alt="image-5.png" /></p>
  </li>
  <li>
    <p>R-Squared (R2) : proportional improvement in prediction of the regression model, compared to the mean model (model predicting all given samples as mean value) : 
      - If we were exactly as effective as just predicting the mean, SSres/SStot = 1 and RÂ² = 0
      - If we were perfect (i.e. yi = fi for all cases), SSres/SStot = 0 and RÂ² = 1
  However, it does not take into consideration of <code class="language-plaintext highlighter-rouge">overfitting problem</code>.</p>
    <ul>
      <li>Interpreted as the proportion of total variance that is explained by the model.</li>
      <li>RÂ² is the ratio between how good your model is (RMSE)vs. how good is the naÃ¯ve mean model (RMSE).</li>
    </ul>

    <p><img src="attachment:image-7.png" alt="image-7.png" /></p>
  </li>
</ul>

<h2 id="rmse-vs-rmsle-vs-mae">RMSE vs RMSLE vs MAE</h2>

<p>See links below :</p>
<ul>
  <li>RMSE vs MAE : https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d</li>
  <li>RMSLE metric and defining baseline : https://www.kaggle.com/carlolepelaars/understanding-the-metric-rmsle/notebook</li>
  <li>Model fot metrics : https://www.kaggle.com/residentmario/model-fit-metrics</li>
</ul>

<h2 id="scikit-learn-implementation">Scikit-learn implementation</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### R-square :
</span>
<span class="c1"># sklean
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>

<span class="c1"># hand implemetation 
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">rss_adj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">y_bar_adj</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">ess_adj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_bar_adj</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">rss_adj</span> <span class="o">/</span> <span class="n">ess_adj</span>

<span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>


<span class="c1">### Root Mean Squared Error (RMSE)
</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">squared</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="c1"># hand implemetation 
</span><span class="kn">import</span> <span class="nn">math</span>
<span class="k">def</span> <span class="nf">rmse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="p">((</span><span class="n">y</span><span class="o">-</span><span class="n">y_pred</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span> <span class="p">)</span>

<span class="n">root_mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>


<span class="c1">### Root Mean log Squared Error (RMLSE)
</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_log_error</span>
<span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">squared</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="c1"># or 
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>
<span class="n">RMSLE</span> <span class="o">=</span> <span class="n">rmse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>


<span class="c1">### Mean Absolute Error (MAE) 
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>

<span class="c1"># hand implemetation 
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="k">def</span> <span class="nf">mae</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">y_pred</span><span class="p">)).</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---------------------------------------------------------------------------

NameError                                 Traceback (most recent call last)

&lt;ipython-input-1061-7e2a74a2dd02&gt; in &lt;module&gt;
     14     return 1 - rss_adj / ess_adj
     15 
---&gt; 16 r2_score(y, y_pred)
     17 
     18 


NameError: name 'y_pred' is not defined
</code></pre></div></div>

<h1 id="download-the-data">Download the Data</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PATH</span> <span class="o">=</span> <span class="s">'/Users/rmbp/handson-ml2/datasets/'</span>
<span class="err">!</span><span class="n">ls</span> <span class="p">{</span><span class="n">PATH</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[34mhousing[m[m      [34minception[m[m    [34mjsb_chorales[m[m [34mlifesat[m[m      [34mtitanic[m[m
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">housing</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">f'</span><span class="si">{</span><span class="n">PATH</span><span class="si">}</span><span class="s">/housing/housing.csv'</span><span class="p">)</span>
<span class="n">housing</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-122.23</td>
      <td>37.88</td>
      <td>41.0</td>
      <td>880.0</td>
      <td>129.0</td>
      <td>322.0</td>
      <td>126.0</td>
      <td>8.3252</td>
      <td>452600.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-122.22</td>
      <td>37.86</td>
      <td>21.0</td>
      <td>7099.0</td>
      <td>1106.0</td>
      <td>2401.0</td>
      <td>1138.0</td>
      <td>8.3014</td>
      <td>358500.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-122.24</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1467.0</td>
      <td>190.0</td>
      <td>496.0</td>
      <td>177.0</td>
      <td>7.2574</td>
      <td>352100.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1274.0</td>
      <td>235.0</td>
      <td>558.0</td>
      <td>219.0</td>
      <td>5.6431</td>
      <td>341300.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1627.0</td>
      <td>280.0</td>
      <td>565.0</td>
      <td>259.0</td>
      <td>3.8462</td>
      <td>342200.0</td>
      <td>NEAR BAY</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="automating-the-process-of-fetching-and-loading-the-data">Automating the process of fetching and loading the data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tarfile</span>
<span class="kn">import</span> <span class="nn">urllib</span>

<span class="n">DOWNLOAD_ROOT</span> <span class="o">=</span> <span class="s">"https://raw.githubusercontent.com/ageron/handson-ml2/master/"</span>
<span class="n">HOUSING_PATH</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="s">"/Users/rmbp/Desktop"</span><span class="p">,</span> <span class="s">"housing"</span><span class="p">)</span>
<span class="n">HOUSING_URL</span> <span class="o">=</span> <span class="n">DOWNLOAD_ROOT</span> <span class="o">+</span> <span class="s">"datasets/housing/housing.tgz"</span>
<span class="k">def</span> <span class="nf">fetch_housing_data</span><span class="p">(</span><span class="n">housing_url</span><span class="o">=</span><span class="n">HOUSING_URL</span><span class="p">,</span> <span class="n">housing_path</span><span class="o">=</span><span class="n">HOUSING_PATH</span><span class="p">):</span>
    <span class="n">os</span><span class="p">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">housing_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">tgz_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">housing_path</span><span class="p">,</span> <span class="s">"housing.tgz"</span><span class="p">)</span>
    <span class="n">urllib</span><span class="p">.</span><span class="n">request</span><span class="p">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">housing_url</span><span class="p">,</span> <span class="n">tgz_path</span><span class="p">)</span>
    <span class="n">housing_tgz</span> <span class="o">=</span> <span class="n">tarfile</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">tgz_path</span><span class="p">)</span>
    <span class="n">housing_tgz</span><span class="p">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">HOUSING_PATH</span><span class="p">)</span>
    <span class="n">housing_tgz</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fetch_housing_data</span><span class="p">(</span><span class="n">HOUSING_URL</span><span class="p">,</span><span class="n">HOUSING_PATH</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="k">def</span> <span class="nf">load_housing_data</span><span class="p">(</span><span class="n">housing_path</span><span class="o">=</span><span class="n">HOUSING_PATH</span><span class="p">):</span>
    <span class="n">csv_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">housing_path</span><span class="p">,</span> <span class="s">"housing.csv"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csv_path</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">load_housing_data</span><span class="p">().</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-122.23</td>
      <td>37.88</td>
      <td>41.0</td>
      <td>880.0</td>
      <td>129.0</td>
      <td>322.0</td>
      <td>126.0</td>
      <td>8.3252</td>
      <td>452600.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-122.22</td>
      <td>37.86</td>
      <td>21.0</td>
      <td>7099.0</td>
      <td>1106.0</td>
      <td>2401.0</td>
      <td>1138.0</td>
      <td>8.3014</td>
      <td>358500.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-122.24</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1467.0</td>
      <td>190.0</td>
      <td>496.0</td>
      <td>177.0</td>
      <td>7.2574</td>
      <td>352100.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1274.0</td>
      <td>235.0</td>
      <td>558.0</td>
      <td>219.0</td>
      <td>5.6431</td>
      <td>341300.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1627.0</td>
      <td>280.0</td>
      <td>565.0</td>
      <td>259.0</td>
      <td>3.8462</td>
      <td>342200.0</td>
      <td>NEAR BAY</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="take-a-quick-look-at-the-data-structure">Take a Quick Look at the Data Structure</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-122.23</td>
      <td>37.88</td>
      <td>41.0</td>
      <td>880.0</td>
      <td>129.0</td>
      <td>322.0</td>
      <td>126.0</td>
      <td>8.3252</td>
      <td>452600.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-122.22</td>
      <td>37.86</td>
      <td>21.0</td>
      <td>7099.0</td>
      <td>1106.0</td>
      <td>2401.0</td>
      <td>1138.0</td>
      <td>8.3014</td>
      <td>358500.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-122.24</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1467.0</td>
      <td>190.0</td>
      <td>496.0</td>
      <td>177.0</td>
      <td>7.2574</td>
      <td>352100.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1274.0</td>
      <td>235.0</td>
      <td>558.0</td>
      <td>219.0</td>
      <td>5.6431</td>
      <td>341300.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1627.0</td>
      <td>280.0</td>
      <td>565.0</td>
      <td>259.0</td>
      <td>3.8462</td>
      <td>342200.0</td>
      <td>NEAR BAY</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 20640 entries, 0 to 20639
Data columns (total 10 columns):
 #   Column              Non-Null Count  Dtype  
---  ------              --------------  -----  
 0   longitude           20640 non-null  float64
 1   latitude            20640 non-null  float64
 2   housing_median_age  20640 non-null  float64
 3   total_rooms         20640 non-null  float64
 4   total_bedrooms      20433 non-null  float64
 5   population          20640 non-null  float64
 6   households          20640 non-null  float64
 7   median_income       20640 non-null  float64
 8   median_house_value  20640 non-null  float64
 9   ocean_proximity     20640 non-null  object 
dtypes: float64(9), object(1)
memory usage: 1.6+ MB
</code></pre></div></div>

<p>There are 20,640 instances in the dataset.
Notice that the <code class="language-plaintext highlighter-rouge">total_bedrooms</code> attribute has only 20,433 nonnull values, meaning that 207 districts are <code class="language-plaintext highlighter-rouge">missing</code>
this feature.
All attributes are numerical, except the <code class="language-plaintext highlighter-rouge">ocean_proximity</code> field. Its type is object. Since we loaded this data from a CSV file, it must be a text attribute. : the values in the <code class="language-plaintext highlighter-rouge">ocean_proximity</code> column were repetitive,
which means that it is probably a <code class="language-plaintext highlighter-rouge">categorical</code> attribute.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">[</span><span class="s">'ocean_proximity'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;1H OCEAN     9136
INLAND        6551
NEAR OCEAN    2658
NEAR BAY      2290
ISLAND           5
Name: ocean_proximity, dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">.</span><span class="n">describe</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s">'all'</span><span class="p">).</span><span class="n">T</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>unique</th>
      <th>top</th>
      <th>freq</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>longitude</th>
      <td>20640.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-119.569704</td>
      <td>2.003532</td>
      <td>-124.35</td>
      <td>-121.8</td>
      <td>-118.49</td>
      <td>-118.01</td>
      <td>-114.31</td>
    </tr>
    <tr>
      <th>latitude</th>
      <td>20640.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>35.631861</td>
      <td>2.135952</td>
      <td>32.54</td>
      <td>33.93</td>
      <td>34.26</td>
      <td>37.71</td>
      <td>41.95</td>
    </tr>
    <tr>
      <th>housing_median_age</th>
      <td>20640.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>28.639486</td>
      <td>12.585558</td>
      <td>1.0</td>
      <td>18.0</td>
      <td>29.0</td>
      <td>37.0</td>
      <td>52.0</td>
    </tr>
    <tr>
      <th>total_rooms</th>
      <td>20640.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2635.763081</td>
      <td>2181.615252</td>
      <td>2.0</td>
      <td>1447.75</td>
      <td>2127.0</td>
      <td>3148.0</td>
      <td>39320.0</td>
    </tr>
    <tr>
      <th>total_bedrooms</th>
      <td>20433.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>537.870553</td>
      <td>421.38507</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>435.0</td>
      <td>647.0</td>
      <td>6445.0</td>
    </tr>
    <tr>
      <th>population</th>
      <td>20640.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1425.476744</td>
      <td>1132.462122</td>
      <td>3.0</td>
      <td>787.0</td>
      <td>1166.0</td>
      <td>1725.0</td>
      <td>35682.0</td>
    </tr>
    <tr>
      <th>households</th>
      <td>20640.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>499.53968</td>
      <td>382.329753</td>
      <td>1.0</td>
      <td>280.0</td>
      <td>409.0</td>
      <td>605.0</td>
      <td>6082.0</td>
    </tr>
    <tr>
      <th>median_income</th>
      <td>20640.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.870671</td>
      <td>1.899822</td>
      <td>0.4999</td>
      <td>2.5634</td>
      <td>3.5348</td>
      <td>4.74325</td>
      <td>15.0001</td>
    </tr>
    <tr>
      <th>median_house_value</th>
      <td>20640.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>206855.816909</td>
      <td>115395.615874</td>
      <td>14999.0</td>
      <td>119600.0</td>
      <td>179700.0</td>
      <td>264725.0</td>
      <td>500001.0</td>
    </tr>
    <tr>
      <th>ocean_proximity</th>
      <td>20640</td>
      <td>5</td>
      <td>&lt;1H OCEAN</td>
      <td>9136</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>

<p>hist() method on the whole dataset will plot a histogram for each numerical attribute</p>
<ul>
  <li>A <code class="language-plaintext highlighter-rouge">histogram</code> is used for <code class="language-plaintext highlighter-rouge">continuous data</code>, where the <code class="language-plaintext highlighter-rouge">bins</code> represent <code class="language-plaintext highlighter-rouge">ranges of data</code>, counts the data points in each bin, and shows the bins on the x-axis and the counts on the y-axis. : https://towardsdatascience.com/histograms-and-density-plots-in-python-f6bda88f5ac0</li>
  <li>A <code class="language-plaintext highlighter-rouge">bar chart</code> is a plot of <code class="language-plaintext highlighter-rouge">categorical</code> variables.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1">#This tells Jupyter to set up Matplotlib so it uses Jupyterâ€™s own backend.
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">housing</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_28_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># plot 'median_house_value'
</span><span class="n">housing</span><span class="p">[</span><span class="s">'median_house_value'</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'hist'</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span> <span class="mi">60</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;AxesSubplot:ylabel='Frequency'&gt;
</code></pre></div></div>

<p><img src="output_29_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">[</span><span class="s">'ocean_proximity'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span> <span class="s">'barh'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;AxesSubplot:&gt;
</code></pre></div></div>

<p><img src="output_30_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">housing</span><span class="p">[</span><span class="s">'median_income'</span><span class="p">].</span><span class="n">describe</span><span class="p">()).</span><span class="n">T</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>median_income</th>
      <td>20640.0</td>
      <td>3.870671</td>
      <td>1.899822</td>
      <td>0.4999</td>
      <td>2.5634</td>
      <td>3.5348</td>
      <td>4.74325</td>
      <td>15.0001</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">housing</span><span class="p">.</span><span class="n">median_income</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="mf">15.000100</span> <span class="o">-</span> <span class="mf">0.499900</span><span class="p">)</span><span class="o">/</span><span class="mf">0.1</span><span class="p">),</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s">'black'</span>
                           <span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s">'blue'</span><span class="p">)</span>
<span class="c1"># bins = int((15.000100 - 0.499900)/0.1) : We choose the number of bins with an interval lenght of 100â‚¬
</span></code></pre></div></div>

<p><img src="output_32_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">housing</span><span class="p">[</span><span class="s">'housing_median_age'</span><span class="p">].</span><span class="n">describe</span><span class="p">()).</span><span class="n">T</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>housing_median_age</th>
      <td>20640.0</td>
      <td>28.639486</td>
      <td>12.585558</td>
      <td>1.0</td>
      <td>18.0</td>
      <td>29.0</td>
      <td>37.0</td>
      <td>52.0</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">housing</span><span class="p">.</span><span class="n">housing_median_age</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="mf">52.000000</span> <span class="o">-</span> <span class="mf">1.000000</span><span class="p">)</span><span class="o">/</span><span class="mi">1</span><span class="p">)</span>
                           <span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'blue'</span>
                           <span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s">'black'</span><span class="p">)</span>
<span class="n">bins</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,
       14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,
       27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.,
       40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52.])
</code></pre></div></div>

<p><img src="output_34_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Target
</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">housing</span><span class="p">[</span><span class="s">'median_house_value'</span><span class="p">].</span><span class="n">describe</span><span class="p">()).</span><span class="n">T</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>median_house_value</th>
      <td>20640.0</td>
      <td>206855.816909</td>
      <td>115395.615874</td>
      <td>14999.0</td>
      <td>119600.0</td>
      <td>179700.0</td>
      <td>264725.0</td>
      <td>500001.0</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">housing</span><span class="p">.</span><span class="n">median_house_value</span> <span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="mf">500001.000000</span> <span class="o">-</span> <span class="mf">14999.000000</span><span class="p">)</span><span class="o">/</span><span class="mi">10000</span><span class="p">)</span>
                           <span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'blue'</span>
                           <span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s">'black'</span><span class="p">)</span>
<span class="n">bins</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([ 14999.        ,  25103.20833333,  35207.41666667,  45311.625     ,
        55415.83333333,  65520.04166667,  75624.25      ,  85728.45833333,
        95832.66666667, 105936.875     , 116041.08333333, 126145.29166667,
       136249.5       , 146353.70833333, 156457.91666667, 166562.125     ,
       176666.33333333, 186770.54166667, 196874.75      , 206978.95833333,
       217083.16666667, 227187.375     , 237291.58333333, 247395.79166667,
       257500.        , 267604.20833333, 277708.41666667, 287812.625     ,
       297916.83333333, 308021.04166667, 318125.25      , 328229.45833333,
       338333.66666667, 348437.875     , 358542.08333333, 368646.29166667,
       378750.5       , 388854.70833333, 398958.91666667, 409063.125     ,
       419167.33333333, 429271.54166667, 439375.75      , 449479.95833333,
       459584.16666667, 469688.375     , 479792.58333333, 489896.79166667,
       500001.        ])
</code></pre></div></div>

<p><img src="output_36_1.png" alt="png" /></p>

<p>From the figure below, we can see <code class="language-plaintext highlighter-rouge">how the data was computed</code> :</p>
<ul>
  <li>We can see that <code class="language-plaintext highlighter-rouge">median_income</code> was <code class="language-plaintext highlighter-rouge">scaled</code> and <code class="language-plaintext highlighter-rouge">capped</code> at 15 (actually, 15.0001) for higher median incomes, and at 0.5 (actually, 0.4999) for lower median incomes. The numbers represent roughly tens of thousands of dollars.</li>
  <li>The <code class="language-plaintext highlighter-rouge">housing median age</code> and the <code class="language-plaintext highlighter-rouge">median house value</code> were also <code class="language-plaintext highlighter-rouge">capped</code>. The latter may be a serious problem since it is our target attribute. 
In this case<code class="language-plaintext highlighter-rouge">our Machine Learning algorithms may learn that prices never go beyond that limit (â‚¬500,000)</code>. We need to check with our team to see if this is a problem or not. 
If the team needs <code class="language-plaintext highlighter-rouge">precise predictions even beyond â‚¬500,000</code>, then you have two options:
    <ul>
      <li>Collect proper labels for the districts whose labels were capped.</li>
      <li>Remove those districts from the training set (and also from the test set, since your system should not be evaluated poorly if it predicts values beyond â‚¬500,000).</li>
    </ul>
  </li>
</ul>

<p>We can also see that :</p>
<ul>
  <li>These attributes have very different scales.</li>
  <li>Many histograms are tail-heavy : they extend much farther to the right of the median than to the left.</li>
</ul>

<h1 id="create-a-test-set">Create a Test Set</h1>

<p>We ahve only taken a quick glance at the data : numeric / categorical features, missing values, scale of attributes, distribution, how values are computed, distribution of the target variable. 
Itâ€™s enough. Why ?</p>
<ul>
  <li>if you look at the test set, you may stumble upon some seemingly interesting pattern in the test data that leads you to select a particular kind of Machine Learning model. When you estimate the generalization error using the test set, your estimate will be too optimistic, and you will launch a system that will not perform as well as expected. This is called <code class="language-plaintext highlighter-rouge">data snooping bias</code>.</li>
</ul>

<h2 id="train-and-test-set-stability">Train and test set stability</h2>

<p>Creating a test set is theoretically simple: pick some instances randomly, typically 20% of the dataset</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="k">def</span> <span class="nf">split_train_test</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">test_ratio</span><span class="p">):</span>
    <span class="n">shuffled_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
    <span class="n">test_set_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">test_ratio</span><span class="p">)</span>
    <span class="n">test_indices</span> <span class="o">=</span> <span class="n">shuffled_indices</span><span class="p">[:</span><span class="n">test_set_size</span><span class="p">]</span>
    <span class="n">train_indices</span> <span class="o">=</span> <span class="n">shuffled_indices</span><span class="p">[</span><span class="n">test_set_size</span><span class="p">:]</span>
    <span class="k">return</span> <span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_indices</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">split_train_test</span><span class="p">(</span><span class="n">housing</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_set</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>16512
4128
</code></pre></div></div>

<p>Well, this works, but it is not perfect: if you <code class="language-plaintext highlighter-rouge">run the program again</code>, it will generate a <code class="language-plaintext highlighter-rouge">different test set!</code></p>
<ul>
  <li>Over time, you (or your Machine Learning algorithms) will get to see the whole dataset, which is what you want to avoid.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># first run test set
</span><span class="n">split_train_test</span><span class="p">(</span><span class="n">housing</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12003</th>
      <td>-117.57</td>
      <td>33.90</td>
      <td>7.0</td>
      <td>3797.0</td>
      <td>850.0</td>
      <td>2369.0</td>
      <td>720.0</td>
      <td>3.5525</td>
      <td>137600.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>13304</th>
      <td>-117.63</td>
      <td>34.09</td>
      <td>19.0</td>
      <td>3490.0</td>
      <td>816.0</td>
      <td>2818.0</td>
      <td>688.0</td>
      <td>2.8977</td>
      <td>126200.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>19037</th>
      <td>-121.99</td>
      <td>38.36</td>
      <td>35.0</td>
      <td>2728.0</td>
      <td>451.0</td>
      <td>1290.0</td>
      <td>452.0</td>
      <td>3.2768</td>
      <td>117600.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>9871</th>
      <td>-121.82</td>
      <td>36.61</td>
      <td>24.0</td>
      <td>2437.0</td>
      <td>438.0</td>
      <td>1430.0</td>
      <td>444.0</td>
      <td>3.8015</td>
      <td>169100.0</td>
      <td>&lt;1H OCEAN</td>
    </tr>
    <tr>
      <th>16526</th>
      <td>-121.20</td>
      <td>37.80</td>
      <td>37.0</td>
      <td>311.0</td>
      <td>61.0</td>
      <td>171.0</td>
      <td>54.0</td>
      <td>4.0972</td>
      <td>101800.0</td>
      <td>INLAND</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># second run test set
</span><span class="n">split_train_test</span><span class="p">(</span><span class="n">housing</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5709</th>
      <td>-118.23</td>
      <td>34.21</td>
      <td>32.0</td>
      <td>1464.0</td>
      <td>406.0</td>
      <td>693.0</td>
      <td>380.0</td>
      <td>2.5463</td>
      <td>200000.0</td>
      <td>&lt;1H OCEAN</td>
    </tr>
    <tr>
      <th>16381</th>
      <td>-121.30</td>
      <td>38.02</td>
      <td>4.0</td>
      <td>1515.0</td>
      <td>384.0</td>
      <td>491.0</td>
      <td>348.0</td>
      <td>2.8523</td>
      <td>87500.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>16458</th>
      <td>-121.30</td>
      <td>38.13</td>
      <td>26.0</td>
      <td>2256.0</td>
      <td>360.0</td>
      <td>937.0</td>
      <td>372.0</td>
      <td>5.0528</td>
      <td>153700.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>8613</th>
      <td>-118.37</td>
      <td>33.87</td>
      <td>23.0</td>
      <td>1829.0</td>
      <td>331.0</td>
      <td>891.0</td>
      <td>356.0</td>
      <td>6.5755</td>
      <td>359900.0</td>
      <td>&lt;1H OCEAN</td>
    </tr>
    <tr>
      <th>2738</th>
      <td>-115.56</td>
      <td>32.78</td>
      <td>35.0</td>
      <td>1185.0</td>
      <td>202.0</td>
      <td>615.0</td>
      <td>191.0</td>
      <td>4.6154</td>
      <td>86200.0</td>
      <td>INLAND</td>
    </tr>
  </tbody>
</table>
</div>

<p>Solution :</p>
<ul>
  <li>One solution is to save the test set on the first run and then load it in subsequent runs.</li>
  <li>Another option is to set the random number generatorâ€™s seed (e.g., with np.ran dom.seed(42))14 before calling np.random.permutation() so that it always generates the same shuffled indices :</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">split_train_test</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">test_ratio</span><span class="p">):</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1997</span><span class="p">)</span>
    <span class="n">shuffled_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
    <span class="n">test_set_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">test_ratio</span><span class="p">)</span>
    <span class="n">test_indices</span> <span class="o">=</span> <span class="n">shuffled_indices</span><span class="p">[:</span><span class="n">test_set_size</span><span class="p">]</span>
    <span class="n">train_indices</span> <span class="o">=</span> <span class="n">shuffled_indices</span><span class="p">[</span><span class="n">test_set_size</span><span class="p">:]</span>
    <span class="k">return</span> <span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_indices</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># first run test set
</span><span class="n">split_train_test</span><span class="p">(</span><span class="n">housing</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9009</th>
      <td>-118.60</td>
      <td>34.07</td>
      <td>16.0</td>
      <td>319.0</td>
      <td>59.0</td>
      <td>149.0</td>
      <td>64.0</td>
      <td>4.6250</td>
      <td>433300.0</td>
      <td>&lt;1H OCEAN</td>
    </tr>
    <tr>
      <th>17779</th>
      <td>-121.83</td>
      <td>37.38</td>
      <td>15.0</td>
      <td>4430.0</td>
      <td>992.0</td>
      <td>3278.0</td>
      <td>1018.0</td>
      <td>4.5533</td>
      <td>209900.0</td>
      <td>&lt;1H OCEAN</td>
    </tr>
    <tr>
      <th>20209</th>
      <td>-119.21</td>
      <td>34.28</td>
      <td>27.0</td>
      <td>2219.0</td>
      <td>312.0</td>
      <td>937.0</td>
      <td>315.0</td>
      <td>5.7601</td>
      <td>281100.0</td>
      <td>NEAR OCEAN</td>
    </tr>
    <tr>
      <th>3170</th>
      <td>-119.69</td>
      <td>36.41</td>
      <td>38.0</td>
      <td>1016.0</td>
      <td>202.0</td>
      <td>540.0</td>
      <td>187.0</td>
      <td>2.2885</td>
      <td>75000.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>2200</th>
      <td>-119.85</td>
      <td>36.83</td>
      <td>15.0</td>
      <td>2563.0</td>
      <td>335.0</td>
      <td>1080.0</td>
      <td>356.0</td>
      <td>6.7181</td>
      <td>160300.0</td>
      <td>INLAND</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># second run test set
</span><span class="n">split_train_test</span><span class="p">(</span><span class="n">housing</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9009</th>
      <td>-118.60</td>
      <td>34.07</td>
      <td>16.0</td>
      <td>319.0</td>
      <td>59.0</td>
      <td>149.0</td>
      <td>64.0</td>
      <td>4.6250</td>
      <td>433300.0</td>
      <td>&lt;1H OCEAN</td>
    </tr>
    <tr>
      <th>17779</th>
      <td>-121.83</td>
      <td>37.38</td>
      <td>15.0</td>
      <td>4430.0</td>
      <td>992.0</td>
      <td>3278.0</td>
      <td>1018.0</td>
      <td>4.5533</td>
      <td>209900.0</td>
      <td>&lt;1H OCEAN</td>
    </tr>
    <tr>
      <th>20209</th>
      <td>-119.21</td>
      <td>34.28</td>
      <td>27.0</td>
      <td>2219.0</td>
      <td>312.0</td>
      <td>937.0</td>
      <td>315.0</td>
      <td>5.7601</td>
      <td>281100.0</td>
      <td>NEAR OCEAN</td>
    </tr>
    <tr>
      <th>3170</th>
      <td>-119.69</td>
      <td>36.41</td>
      <td>38.0</td>
      <td>1016.0</td>
      <td>202.0</td>
      <td>540.0</td>
      <td>187.0</td>
      <td>2.2885</td>
      <td>75000.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>2200</th>
      <td>-119.85</td>
      <td>36.83</td>
      <td>15.0</td>
      <td>2563.0</td>
      <td>335.0</td>
      <td>1080.0</td>
      <td>356.0</td>
      <td>6.7181</td>
      <td>160300.0</td>
      <td>INLAND</td>
    </tr>
  </tbody>
</table>
</div>

<p>But both these solutions will break the next time you fetch an <code class="language-plaintext highlighter-rouge">updated dataset</code>.</p>

<p>If the dataset is updated, we want to ensure that the
<code class="language-plaintext highlighter-rouge">test set</code> will remain <code class="language-plaintext highlighter-rouge">consistent across multiple runs</code>, even if you refresh the dataset : The <code class="language-plaintext highlighter-rouge">new test set</code> will contain <code class="language-plaintext highlighter-rouge">20% of the new instances</code>, but <code class="language-plaintext highlighter-rouge">it will not contain any
instance that was previously in the training set.</code></p>

<p>To have a stable train/test split even after updating the dataset, a common solution is to
<code class="language-plaintext highlighter-rouge">use each instanceâ€™s identifier to decide whether or not it should go in the test set</code>
(assuming instances have a unique and immutable identifier). For example, we could
compute a <code class="language-plaintext highlighter-rouge">hash</code> of each instanceâ€™s identifier and <code class="language-plaintext highlighter-rouge">put that instance in the test set</code> if <code class="language-plaintext highlighter-rouge">the
hash is lower than or equal to 20% of the maximum hash value.</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">from</span> <span class="nn">zlib</span> <span class="kn">import</span> <span class="n">crc32</span>

<span class="k">def</span> <span class="nf">test_set_check</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="n">test_ratio</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">crc32</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">int64</span><span class="p">(</span><span class="n">identifier</span><span class="p">))</span> <span class="o">&amp;</span> <span class="mh">0xffffffff</span> <span class="o">&lt;</span> <span class="n">test_ratio</span> <span class="o">*</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>

<span class="c1"># crc32(np.int64(identifier)) = create a hash from a given value
# crc32(np.int64(identifier)) &amp; 0xffffffff = make sure the hash value does not exceed 2^32 (or 4294967296).
# crc32(np.int64(identifier)) &amp; 0xffffffff &lt; test_ratio * 2**32. 
# crc32(np.int64(identifier)) &amp; 0xffffffff &lt; test_ratio * 2**32
#    This line returns True or False. Let test_ratio be 0.2. 
#    Then, any hash value less than 0.2 * 4294967296 returns True and will be 
#    added to the test set; otherwise, it returns False and will be added to the training set. */
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">split_train_test_by_id</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">test_ratio</span><span class="p">,</span> <span class="n">id_column</span><span class="p">):</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">id_column</span><span class="p">]</span> <span class="c1"># compute a hash of each instanceâ€™s identifier
</span>    <span class="n">in_test_set</span> <span class="o">=</span> <span class="n">ids</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">id_</span><span class="p">:</span> <span class="n">test_set_check</span><span class="p">(</span><span class="n">id_</span><span class="p">,</span> <span class="n">test_ratio</span><span class="p">))</span> <span class="c1"># if hash is lower than or equal to 20% of the maximum hash value
</span>    <span class="k">return</span> <span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="o">~</span><span class="n">in_test_set</span><span class="p">],</span> <span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">in_test_set</span><span class="p">]</span>
</code></pre></div></div>

<p>Unfortunately, the housing dataset does not have an identifier column. The simplest solution is to use the row index as the ID:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_with_id</span> <span class="o">=</span> <span class="n">housing</span><span class="p">.</span><span class="n">reset_index</span><span class="p">()</span> <span class="c1"># adds an `index` column
</span><span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">split_train_test_by_id</span><span class="p">(</span><span class="n">housing_with_id</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s">"index"</span><span class="p">)</span>
</code></pre></div></div>

<p>If we use the <code class="language-plaintext highlighter-rouge">row index</code> as a <code class="language-plaintext highlighter-rouge">unique identifier</code>, <code class="language-plaintext highlighter-rouge">you need to make sure that new data
gets appended to the end of the dataset and that no row ever gets deleted</code>.
If this is not possible, then we can try to use <code class="language-plaintext highlighter-rouge">the most stable features to build a unique identifier</code>.</p>

<p>For example, a districtâ€™s latitude and longitude are guaranteed to be stable for a few million years, so you could combine them into an ID like so:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_with_id</span><span class="p">[</span><span class="s">"id"</span><span class="p">]</span> <span class="o">=</span> <span class="n">housing</span><span class="p">[</span><span class="s">"longitude"</span><span class="p">]</span> <span class="o">*</span> <span class="mi">1000</span> <span class="o">+</span> <span class="n">housing</span><span class="p">[</span><span class="s">"latitude"</span><span class="p">]</span>
<span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">split_train_test_by_id</span><span class="p">(</span><span class="n">housing_with_id</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s">"id"</span><span class="p">)</span>
</code></pre></div></div>

<p>See explanation of this method in : https://ichi.pro/fr/ameliorez-la-repartition-des-tests-de-train-avec-la-fonction-de-hachage-267796356735483
 and https://datascience.stackexchange.com/questions/51348/splitting-train-test-sets-by-an-identifier</p>

<h2 id="train--test-split-using-sckit-learn">Train / Test split using Sckit-learn</h2>

<p>Scikit-Learn provides a few functions to split datasets into multiple subsets in various
ways. The simplest function is <code class="language-plaintext highlighter-rouge">train_test_split()</code>, which does pretty much the
same thing as the function <code class="language-plaintext highlighter-rouge">split_train_test()</code>, with a couple of additional features :</p>
<ul>
  <li>First, there is a random_state parameter <code class="language-plaintext highlighter-rouge">random_state</code> that allows you to set the random generator
seed and a test size <code class="language-plaintext highlighter-rouge">test_size</code>.</li>
  <li>Second, we can pass it multiple datasets with an <code class="language-plaintext highlighter-rouge">identical number of rows</code>, and
it will split them on the <code class="language-plaintext highlighter-rouge">same indices</code> (this is very useful, for example, if you have a
separate DataFrame for labels):</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">housing</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">1997</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="sampling-bias-in-test-set">Sampling bias in Test set</h1>

<p>Using <code class="language-plaintext highlighter-rouge">train_test_split</code>method, we using purely random sampling methods to generate our test set. This is generally fine <code class="language-plaintext highlighter-rouge">if our dataset is large enough</code> (especially relative to the number of attributes), but if it
is not, we run the <code class="language-plaintext highlighter-rouge">risk of introducing a significant sampling bias</code>.</p>

<p>If an attribute (continues or categorical) is important (after discussing with experts for exemple) : We may want to ensure that the test set is representative of the <code class="language-plaintext highlighter-rouge">various categories</code> of that variable in the whole dataset.</p>

<p>Suppose that the <code class="language-plaintext highlighter-rouge">median income</code> is a very important attribute to predict median housing prices.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">[</span><span class="s">'median_income'</span><span class="p">].</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>count    20640.000000
mean         3.870671
std          1.899822
min          0.499900
25%          2.563400
50%          3.534800
75%          4.743250
max         15.000100
Name: median_income, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">housing</span><span class="p">[</span><span class="s">'median_income'</span><span class="p">]</span>
         <span class="c1">#, bins = int( (housing['median_income'].max() - housing['median_income'].min()) / 0.5)
</span>         <span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">60</span>
         <span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'blue'</span>
         <span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s">'black'</span>
        <span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_65_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">[</span><span class="s">"income_cat"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">cut</span><span class="p">(</span><span class="n">housing</span><span class="p">[</span><span class="s">"median_income"</span><span class="p">],</span>
<span class="n">bins</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">inf</span><span class="p">],</span>
<span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">[</span><span class="s">'income_cat'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">cut</span><span class="p">(</span> <span class="n">housing</span><span class="p">[</span><span class="s">'median_income'</span><span class="p">]</span>
                               <span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">inf</span><span class="p">]</span>
                               <span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
                        <span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">[</span><span class="s">"income_cat"</span><span class="p">].</span><span class="n">hist</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;AxesSubplot:&gt;
</code></pre></div></div>

<p><img src="output_68_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">[</span><span class="s">"income_cat"</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">housing</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3    0.350581
2    0.318847
4    0.176308
5    0.114438
1    0.039826
Name: income_cat, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedShuffleSplit</span>
<span class="n">split</span> <span class="o">=</span> <span class="n">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">split</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">housing</span><span class="p">,</span> <span class="n">housing</span><span class="p">[</span><span class="s">"income_cat"</span><span class="p">]):</span>
        <span class="n">strat_train_set</span> <span class="o">=</span> <span class="n">housing</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
        <span class="n">strat_test_set</span> <span class="o">=</span> <span class="n">housing</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">strat_train_set</span><span class="p">[</span><span class="s">"income_cat"</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">strat_train_set</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3    0.350594
2    0.318859
4    0.176296
5    0.114462
1    0.039789
Name: income_cat, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">strat_test_set</span><span class="p">[</span><span class="s">"income_cat"</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">strat_test_set</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3    0.350533
2    0.318798
4    0.176357
5    0.114341
1    0.039971
Name: income_cat, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">income_cat_proportions</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="s">"income_cat"</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">housing</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">compare_props</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s">"Overall"</span><span class="p">:</span> <span class="n">income_cat_proportions</span><span class="p">(</span><span class="n">housing</span><span class="p">),</span>
    <span class="s">"Stratified"</span><span class="p">:</span> <span class="n">income_cat_proportions</span><span class="p">(</span><span class="n">strat_test_set</span><span class="p">),</span>
    <span class="s">"Random"</span><span class="p">:</span> <span class="n">income_cat_proportions</span><span class="p">(</span><span class="n">test_set</span><span class="p">),</span>
<span class="p">}).</span><span class="n">sort_index</span><span class="p">()</span>
<span class="n">compare_props</span><span class="p">[</span><span class="s">"Rand. %error"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">compare_props</span><span class="p">[</span><span class="s">"Random"</span><span class="p">]</span> <span class="o">/</span> <span class="n">compare_props</span><span class="p">[</span><span class="s">"Overall"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">100</span>
<span class="n">compare_props</span><span class="p">[</span><span class="s">"Strat. %error"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">compare_props</span><span class="p">[</span><span class="s">"Stratified"</span><span class="p">]</span> <span class="o">/</span> <span class="n">compare_props</span><span class="p">[</span><span class="s">"Overall"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">100</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">compare_props</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Overall</th>
      <th>Stratified</th>
      <th>Random</th>
      <th>Rand. %error</th>
      <th>Strat. %error</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.039826</td>
      <td>0.039971</td>
      <td>0.040213</td>
      <td>0.973236</td>
      <td>0.364964</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.318847</td>
      <td>0.318798</td>
      <td>0.324370</td>
      <td>1.732260</td>
      <td>-0.015195</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.350581</td>
      <td>0.350533</td>
      <td>0.358527</td>
      <td>2.266446</td>
      <td>-0.013820</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.176308</td>
      <td>0.176357</td>
      <td>0.167393</td>
      <td>-5.056334</td>
      <td>0.027480</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.114438</td>
      <td>0.114341</td>
      <td>0.109496</td>
      <td>-4.318374</td>
      <td>-0.084674</td>
    </tr>
  </tbody>
</table>
</div>

<ul>
  <li>Further analysis later</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">set_</span> <span class="ow">in</span> <span class="p">(</span><span class="n">strat_train_set</span><span class="p">,</span> <span class="n">strat_test_set</span><span class="p">):</span>
    <span class="n">set_</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">"income_cat"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="discover-and-visualize-the-data-to-gain-insights">Discover and Visualize the Data to Gain Insights</h1>

<p>First, we make sure that we have put <code class="language-plaintext highlighter-rouge">the test set aside</code> and we are only <code class="language-plaintext highlighter-rouge">exploring the training
set.</code> Also, if the training set is very large, you may want to sample an exploration
set, to make manipulations easy and fast. 
In our case, the set is quite small, so we can just work directly on the full set.</p>
<ul>
  <li>Letâ€™s create a <code class="language-plaintext highlighter-rouge">copy</code> so that you can play with it <code class="language-plaintext highlighter-rouge">without harming the training set</code>:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span> <span class="o">=</span> <span class="n">strat_train_set</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
      <th>income_cat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12655</th>
      <td>-121.46</td>
      <td>38.52</td>
      <td>29.0</td>
      <td>3873.0</td>
      <td>797.0</td>
      <td>2237.0</td>
      <td>706.0</td>
      <td>2.1736</td>
      <td>72100.0</td>
      <td>INLAND</td>
      <td>2</td>
    </tr>
    <tr>
      <th>15502</th>
      <td>-117.23</td>
      <td>33.09</td>
      <td>7.0</td>
      <td>5320.0</td>
      <td>855.0</td>
      <td>2015.0</td>
      <td>768.0</td>
      <td>6.3373</td>
      <td>279600.0</td>
      <td>NEAR OCEAN</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2908</th>
      <td>-119.04</td>
      <td>35.37</td>
      <td>44.0</td>
      <td>1618.0</td>
      <td>310.0</td>
      <td>667.0</td>
      <td>300.0</td>
      <td>2.8750</td>
      <td>82700.0</td>
      <td>INLAND</td>
      <td>2</td>
    </tr>
    <tr>
      <th>14053</th>
      <td>-117.13</td>
      <td>32.75</td>
      <td>24.0</td>
      <td>1877.0</td>
      <td>519.0</td>
      <td>898.0</td>
      <td>483.0</td>
      <td>2.2264</td>
      <td>112500.0</td>
      <td>NEAR OCEAN</td>
      <td>2</td>
    </tr>
    <tr>
      <th>20496</th>
      <td>-118.70</td>
      <td>34.28</td>
      <td>27.0</td>
      <td>3536.0</td>
      <td>646.0</td>
      <td>1837.0</td>
      <td>580.0</td>
      <td>4.4964</td>
      <td>238300.0</td>
      <td>&lt;1H OCEAN</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>

<ul>
  <li>Since we have <code class="language-plaintext highlighter-rouge">geographic information</code> (lon / lat), letâ€™s create a <code class="language-plaintext highlighter-rouge">scatterplot</code> of all districts to visualize the data : doc of a scatterplot parameter https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s">'scatter'</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="s">'longitude'</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s">'latitude'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;AxesSubplot:xlabel='longitude', ylabel='latitude'&gt;
</code></pre></div></div>

<p><img src="output_82_1.png" alt="png" /></p>

<p>Scatter plots work well for hundreds of observations but overplotting becomes an issue once the number of observations gets into tens of thousands.</p>

<p>We can see that in some areas, there are vast numbers of dots, so it is hard to see any particular
pattern.</p>

<p>Simple options to address overplotting :</p>
<ul>
  <li>reducing the point size : usisng the <code class="language-plaintext highlighter-rouge">s</code> parameter - This parameter indicates the marker size.</li>
  <li>alpha blending : using <code class="language-plaintext highlighter-rouge">alpha</code> parameter This option indicates the blending value, between 0 (transparent) and 1 (opaque).</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s">'scatter'</span> <span class="p">,</span><span class="n">x</span> <span class="o">=</span> <span class="s">'longitude'</span> <span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="s">'latitude'</span> <span class="p">,</span> <span class="n">s</span><span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;AxesSubplot:xlabel='longitude', ylabel='latitude'&gt;
</code></pre></div></div>

<p><img src="output_84_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s">'scatter'</span> <span class="p">,</span><span class="n">x</span> <span class="o">=</span> <span class="s">'longitude'</span> <span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="s">'latitude'</span> <span class="p">,</span> <span class="n">alpha</span><span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;AxesSubplot:xlabel='longitude', ylabel='latitude'&gt;
</code></pre></div></div>

<p><img src="output_85_1.png" alt="png" /></p>

<p>We can get the names of the cities in the map and conclude which have the highest density - Many article covers this subject - we will do it later</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># To save a picture in our folder project :
</span><span class="n">IMAGES_PATH</span> <span class="o">=</span> <span class="s">"/Users/rmbp/Desktop/housing"</span>

<span class="k">def</span> <span class="nf">save_fig</span><span class="p">(</span><span class="n">fig_id</span><span class="p">,</span> <span class="n">tight_layout</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fig_extension</span><span class="o">=</span><span class="s">"png"</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mi">300</span><span class="p">):</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">IMAGES_PATH</span><span class="p">,</span> <span class="n">fig_id</span> <span class="o">+</span> <span class="s">"."</span> <span class="o">+</span> <span class="n">fig_extension</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Saving figure"</span><span class="p">,</span> <span class="n">fig_id</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tight_layout</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="n">fig_extension</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="n">resolution</span><span class="p">)</span>
    
<span class="n">housing</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s">'scatter'</span> <span class="p">,</span><span class="n">x</span> <span class="o">=</span> <span class="s">'longitude'</span> <span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="s">'latitude'</span> <span class="p">,</span> <span class="n">alpha</span><span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'black'</span><span class="p">)</span>
<span class="n">save_fig</span><span class="p">(</span><span class="s">"better_visualization_plot"</span><span class="p">)</span>

 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Saving figure better_visualization_plot
</code></pre></div></div>

<p><img src="output_87_1.png" alt="png" /></p>

<p>We can see the houses price crossing with the population on the map below :</p>
<ul>
  <li>the parameter <code class="language-plaintext highlighter-rouge">s</code> re presenting the <code class="language-plaintext highlighter-rouge">radius of each circle</code> will represents the <code class="language-plaintext highlighter-rouge">districtâ€™s population</code>`</li>
  <li>the paramter <code class="language-plaintext highlighter-rouge">c</code> representing the <code class="language-plaintext highlighter-rouge">color</code> will represents the <code class="language-plaintext highlighter-rouge">price</code>.</li>
  <li>We will use a <code class="language-plaintext highlighter-rouge">predefined color map</code> (option <code class="language-plaintext highlighter-rouge">cmap</code>) called <code class="language-plaintext highlighter-rouge">jet</code>, which ranges from <code class="language-plaintext highlighter-rouge">blue</code> (<code class="language-plaintext highlighter-rouge">low values</code>) to <code class="language-plaintext highlighter-rouge">red</code> (<code class="language-plaintext highlighter-rouge">high prices</code>):</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">"scatter"</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">"longitude"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">"latitude"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
        <span class="n">s</span><span class="o">=</span><span class="n">housing</span><span class="p">[</span><span class="s">"population"</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"population"</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span>
        <span class="n">c</span><span class="o">=</span><span class="s">"median_house_value"</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s">"jet"</span><span class="p">),</span> <span class="n">colorbar</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.legend.Legend at 0x12f4d1650&gt;
</code></pre></div></div>

<p><img src="output_89_1.png" alt="png" /></p>

<ul>
  <li>This image tells us that the housing prices are very much related to the location
(e.g., close to the ocean) and to the population density.</li>
  <li>A <code class="language-plaintext highlighter-rouge">clustering algorithm</code> should be useful for detecting <code class="language-plaintext highlighter-rouge">the main cluster</code> and for adding
<code class="language-plaintext highlighter-rouge">new features that measure the proximity to the cluster centers</code>. 
See later.. Check this blog : https://dev.to/travelleroncode/analyzing-a-dataset-with-unsupervised-learning-31ld</li>
  <li>The <code class="language-plaintext highlighter-rouge">ocean proximity</code> attribute may be useful as well, although in Northern California the housing prices in
coastal districts are not too high, so it is not a simple rule.</li>
</ul>

<h2 id="looking-for-correlations">Looking for correlations</h2>

<p>If we want to explore our data it is good to compute  correlation between numeric variable : <code class="language-plaintext highlighter-rouge">Spearman</code> S and <code class="language-plaintext highlighter-rouge">Pearon</code> P. W can compute them both since the relation between the Spearman (S) and Pearson (P) correlations will give some good information :</p>
<ul>
  <li>
    <p>Briefly, <code class="language-plaintext highlighter-rouge">S is computed on ranks</code> and so depicts <code class="language-plaintext highlighter-rouge">monotonic relationships</code> while <code class="language-plaintext highlighter-rouge">P is on true values</code> and depicts <code class="language-plaintext highlighter-rouge">linear relationships</code>.</p>
  </li>
  <li>
    <p>We the <code class="language-plaintext highlighter-rouge">corr</code> method : By default, method = â€˜Pearsonâ€™</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">s</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">s</span><span class="p">.</span><span class="n">items</span><span class="p">())</span>  
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span><span class="p">.</span><span class="n">corr</span><span class="p">(</span><span class="s">'pearson'</span><span class="p">)</span> 
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.000000</td>
      <td>0.253274</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.253274</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span><span class="p">.</span><span class="n">corr</span><span class="p">(</span><span class="s">'spearman'</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>

<p>This is because ð‘¦ increases <code class="language-plaintext highlighter-rouge">monotonically</code> with ð‘¥ so the <code class="language-plaintext highlighter-rouge">Spearman correlation is perfect</code>, but <code class="language-plaintext highlighter-rouge">not linearly</code>, so the <code class="language-plaintext highlighter-rouge">Pearson correlation is imperfect</code>.</p>

<p>Doing both is interesting because if we have <code class="language-plaintext highlighter-rouge">S &gt; P</code>, that means that we have a <code class="language-plaintext highlighter-rouge">correlation</code> that is <code class="language-plaintext highlighter-rouge">monotonic</code> but <code class="language-plaintext highlighter-rouge">not linear</code>. 
Since it is good to have linearity in statistics (it is easier) we can try to <code class="language-plaintext highlighter-rouge">apply a transformation on ð‘¦</code>(such a log).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">housing</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corr_matrix</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>longitude</th>
      <td>1.000000</td>
      <td>-0.924478</td>
      <td>-0.105823</td>
      <td>0.048909</td>
      <td>0.076686</td>
      <td>0.108071</td>
      <td>0.063146</td>
      <td>-0.019615</td>
      <td>-0.047466</td>
    </tr>
    <tr>
      <th>latitude</th>
      <td>-0.924478</td>
      <td>1.000000</td>
      <td>0.005737</td>
      <td>-0.039245</td>
      <td>-0.072550</td>
      <td>-0.115290</td>
      <td>-0.077765</td>
      <td>-0.075146</td>
      <td>-0.142673</td>
    </tr>
    <tr>
      <th>housing_median_age</th>
      <td>-0.105823</td>
      <td>0.005737</td>
      <td>1.000000</td>
      <td>-0.364535</td>
      <td>-0.325101</td>
      <td>-0.298737</td>
      <td>-0.306473</td>
      <td>-0.111315</td>
      <td>0.114146</td>
    </tr>
    <tr>
      <th>total_rooms</th>
      <td>0.048909</td>
      <td>-0.039245</td>
      <td>-0.364535</td>
      <td>1.000000</td>
      <td>0.929391</td>
      <td>0.855103</td>
      <td>0.918396</td>
      <td>0.200133</td>
      <td>0.135140</td>
    </tr>
    <tr>
      <th>total_bedrooms</th>
      <td>0.076686</td>
      <td>-0.072550</td>
      <td>-0.325101</td>
      <td>0.929391</td>
      <td>1.000000</td>
      <td>0.876324</td>
      <td>0.980167</td>
      <td>-0.009643</td>
      <td>0.047781</td>
    </tr>
    <tr>
      <th>population</th>
      <td>0.108071</td>
      <td>-0.115290</td>
      <td>-0.298737</td>
      <td>0.855103</td>
      <td>0.876324</td>
      <td>1.000000</td>
      <td>0.904639</td>
      <td>0.002421</td>
      <td>-0.026882</td>
    </tr>
    <tr>
      <th>households</th>
      <td>0.063146</td>
      <td>-0.077765</td>
      <td>-0.306473</td>
      <td>0.918396</td>
      <td>0.980167</td>
      <td>0.904639</td>
      <td>1.000000</td>
      <td>0.010869</td>
      <td>0.064590</td>
    </tr>
    <tr>
      <th>median_income</th>
      <td>-0.019615</td>
      <td>-0.075146</td>
      <td>-0.111315</td>
      <td>0.200133</td>
      <td>-0.009643</td>
      <td>0.002421</td>
      <td>0.010869</td>
      <td>1.000000</td>
      <td>0.687151</td>
    </tr>
    <tr>
      <th>median_house_value</th>
      <td>-0.047466</td>
      <td>-0.142673</td>
      <td>0.114146</td>
      <td>0.135140</td>
      <td>0.047781</td>
      <td>-0.026882</td>
      <td>0.064590</td>
      <td>0.687151</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>Now letâ€™s look at how much each attribute correlates with <code class="language-plaintext highlighter-rouge">the median house value</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corr_matrix</span><span class="p">[</span><span class="s">'median_house_value'</span><span class="p">].</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>median_house_value    1.000000
median_income         0.687151
total_rooms           0.135140
housing_median_age    0.114146
households            0.064590
total_bedrooms        0.047781
population           -0.026882
longitude            -0.047466
latitude             -0.142673
Name: median_house_value, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">housing</span><span class="p">.</span><span class="n">corr</span><span class="p">(</span><span class="s">'spearman'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corr_matrix</span><span class="p">[</span><span class="s">'median_house_value'</span><span class="p">].</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>median_house_value    1.000000
median_income         0.675714
total_rooms           0.204476
households            0.110722
total_bedrooms        0.084284
housing_median_age    0.083301
population            0.001309
longitude            -0.071562
latitude             -0.162283
Name: median_house_value, dtype: float64
</code></pre></div></div>

<p>Another way to check for correlation between attributes is to use the pandas
<code class="language-plaintext highlighter-rouge">scatter_matrix()</code> function, which plots every numerical attribute against every
other numerical attribute. ( if we have 11 attribiute, we will plot 11**2 plots )</p>

<p>From the pearson coefficient below, we focus on a few promising
attributes that seem most correlated with the median housing value :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pandas.plotting</span> <span class="kn">import</span> <span class="n">scatter_matrix</span>

<span class="n">attributes</span> <span class="o">=</span> <span class="p">[</span><span class="s">'median_house_value'</span><span class="p">,</span> <span class="s">'median_income'</span><span class="p">,</span> <span class="s">'total_rooms'</span><span class="p">,</span> <span class="s">'housing_median_age'</span> <span class="p">]</span>

<span class="n">scatter_matrix</span><span class="p">(</span><span class="n">housing</span><span class="p">[</span><span class="n">attributes</span><span class="p">],</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[&lt;AxesSubplot:xlabel='median_house_value', ylabel='median_house_value'&gt;,
        &lt;AxesSubplot:xlabel='median_income', ylabel='median_house_value'&gt;,
        &lt;AxesSubplot:xlabel='total_rooms', ylabel='median_house_value'&gt;,
        &lt;AxesSubplot:xlabel='housing_median_age', ylabel='median_house_value'&gt;],
       [&lt;AxesSubplot:xlabel='median_house_value', ylabel='median_income'&gt;,
        &lt;AxesSubplot:xlabel='median_income', ylabel='median_income'&gt;,
        &lt;AxesSubplot:xlabel='total_rooms', ylabel='median_income'&gt;,
        &lt;AxesSubplot:xlabel='housing_median_age', ylabel='median_income'&gt;],
       [&lt;AxesSubplot:xlabel='median_house_value', ylabel='total_rooms'&gt;,
        &lt;AxesSubplot:xlabel='median_income', ylabel='total_rooms'&gt;,
        &lt;AxesSubplot:xlabel='total_rooms', ylabel='total_rooms'&gt;,
        &lt;AxesSubplot:xlabel='housing_median_age', ylabel='total_rooms'&gt;],
       [&lt;AxesSubplot:xlabel='median_house_value', ylabel='housing_median_age'&gt;,
        &lt;AxesSubplot:xlabel='median_income', ylabel='housing_median_age'&gt;,
        &lt;AxesSubplot:xlabel='total_rooms', ylabel='housing_median_age'&gt;,
        &lt;AxesSubplot:xlabel='housing_median_age', ylabel='housing_median_age'&gt;]],
      dtype=object)
</code></pre></div></div>

<p><img src="output_104_1.png" alt="png" /></p>

<p>The main diagonal (top left to bottom right) would be full of straight lines if pandas
plotted each variable against itself, which would not be very useful. So instead pandas
displays a histogram of each attribute. The <code class="language-plaintext highlighter-rouge">diagonal</code> option in scatter_matrix pick between â€˜kdeâ€™ and â€˜histâ€™ for either <code class="language-plaintext highlighter-rouge">Kernel Density Estimation</code> or <code class="language-plaintext highlighter-rouge">Histogram plot</code> in the diagonal.</p>

<p>The most promising attribute to predict <code class="language-plaintext highlighter-rouge">the median house value</code> is <code class="language-plaintext highlighter-rouge">the median
income</code>( Pearson and Spearman correlation coefficient = 0.67 ), so letâ€™s zoom in on their correlation scatterplot :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span> <span class="n">kind</span> <span class="o">=</span> <span class="s">'scatter'</span>
            <span class="p">,</span><span class="n">x</span> <span class="o">=</span> <span class="s">'median_income'</span>
            <span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="s">'median_house_value'</span>
            <span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;AxesSubplot:xlabel='median_income', ylabel='median_house_value'&gt;
</code></pre></div></div>

<p><img src="output_106_1.png" alt="png" /></p>

<p>This plot reveals a few things :</p>
<ul>
  <li>First, the correlation is indeed very strong; we can clearly see the upward trend, and the points are not too dispersed.</li>
  <li>Second, the price cap that we noticed earlier is clearly visible as a horizontal line at $500,000. But this
plot reveals other less obvious straight lines: a horizontal line around $450,000,
another around $350,000, perhaps one around $280,000, and a few more below that, we can see this picks in the histogram above: As result, we  may want to try <code class="language-plaintext highlighter-rouge">removing the corresponding districts</code> to prevent our algorithms
from learning to <code class="language-plaintext highlighter-rouge">reproduce these data quirks</code>.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">[</span><span class="s">'median_house_value'</span><span class="p">].</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>count     16512.000000
mean     207005.322372
std      115701.297250
min       14999.000000
25%      119800.000000
50%      179500.000000
75%      263900.000000
max      500001.000000
Name: median_house_value, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Data picks in the target variable
</span><span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">housing</span><span class="p">[</span><span class="s">'median_house_value'</span><span class="p">]</span>
         <span class="c1">#, bins = int( (housing['median_income'].max() - housing['median_income'].min()) / 0.5)
</span>         <span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="nb">int</span> <span class="p">((</span><span class="mf">500001.000000</span> <span class="o">-</span> <span class="mf">14999.000000</span><span class="p">)</span><span class="o">/</span><span class="mi">1000</span><span class="p">)</span>
         <span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'blue'</span>
         <span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s">'black'</span>
        <span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(array([  3.,   0.,   0.,   0.,   0.,   0.,   0.,   3.,   0.,   0.,   0.,
          2.,   1.,   1.,   0.,   1.,   0.,   4.,   1.,   3.,   1.,   2.,
          4.,   2.,   3.,   4.,   5.,  10.,  13.,  11.,  14.,  11.,  19.,
         17.,  21.,  27.,  24.,  36.,  33.,  39.,  59.,  30.,  53.,  50.,
         38.,  43.,  39.,  45.,  45.,  35.,  54.,  48.,  74.,  59.,  62.,
         54.,  47.,  61.,  51.,  39.,  51.,  41.,  33.,  47.,  37.,  39.,
         64.,  43.,  54.,  59.,  63.,  55., 106.,  73.,  55.,  86.,  53.,
         84.,  74.,  73.,  81.,  70.,  77.,  71.,  64.,  79.,  59.,  45.,
         73.,  50.,  55.,  49.,  55.,  68.,  65.,  62.,  72., 110.,  78.,
         54.,  56.,  66.,  55.,  79.,  53.,  57.,  55.,  60.,  59.,  43.,
         83.,  61.,  54.,  45.,  59.,  52.,  61.,  51.,  55.,  65.,  59.,
         68., 144.,  51.,  75.,  72.,  65.,  75.,  74.,  64.,  68.,  79.,
         57.,  52.,  38., 111.,  76.,  64.,  67.,  77.,  63.,  94.,  75.,
         83.,  76.,  96.,  74., 145.,  73.,  74.,  92.,  88.,  55.,  61.,
         61.,  79.,  68.,  52.,  64.,  53.,  91.,  50.,  57.,  63.,  68.,
         52.,  69.,  59.,  84.,  74.,  65.,  70., 114.,  44.,  56.,  63.,
         70.,  69.,  57.,  51.,  64.,  52.,  37.,  49.,  40.,  59.,  41.,
         35.,  32.,  52.,  47.,  45.,  34.,  47.,  51.,  41.,  37.,  51.,
         53.,  50.,  51.,  44.,  49.,  66.,  44.,  55.,  50.,  49.,  46.,
         38., 107.,  56.,  50.,  48.,  48.,  52.,  60.,  51.,  44.,  52.,
         40.,  41.,  49.,  44.,  43.,  53.,  49.,  27.,  51.,  39.,  43.,
         30.,  47.,  37.,  22.,  50.,  33.,  36.,  42.,  43.,  35.,  20.,
         34.,  40.,  29.,  29.,  37.,  44.,  41.,  39.,  38.,  40.,  40.,
         39.,  35.,  30.,  43.,  34.,  34.,  65.,  21.,  33.,  25.,  29.,
         38.,  22.,  23.,  26.,  30.,  20.,  22.,  24.,  36.,  22.,  25.,
         28.,  26.,  26.,  21.,  24.,  26.,  16.,  15.,   9.,  31.,  12.,
         17.,  19.,  19.,  18.,  17.,  18.,  14.,  15.,  19.,  11.,  22.,
         14.,  18.,  21.,  23.,  15.,   9.,  24.,  16.,  17.,  18.,  23.,
         20.,  28.,  12.,  12.,  21.,  11.,  22.,  17.,  22.,  19.,  22.,
         19.,  25.,  21.,  15.,  14.,  20.,  25.,  22.,  20.,  18.,  22.,
         22.,  16.,  13.,  22.,  75.,  14.,  19.,  19.,  19.,  15.,  22.,
         13.,  18.,  16.,  21.,  16.,  19.,  24.,  11.,  13.,  16.,  17.,
         13.,  11.,  15.,   4.,  18.,   9.,   8.,  26.,   8.,  14.,   6.,
          8.,  12.,  12.,  11.,  10.,  12.,  14.,   5.,  13.,  16.,   7.,
          7.,  11.,  10.,  12.,  14.,  15.,   9.,  11.,  10.,  10.,  22.,
          4.,   2.,  12.,   2.,  10.,  12.,  11.,   2.,   4.,  14.,   9.,
         10.,  10.,   5.,  13.,   5.,  13.,   8.,  13.,   7.,   9.,   3.,
          8.,   8.,  12.,   5.,   5.,   5.,   5.,   2.,  11.,   7.,   6.,
          9.,  11.,   7.,   7.,   7.,   9.,   7.,   7.,   6.,   7.,   8.,
          9.,   6.,   7.,   5.,   2.,  28.,   6.,   5.,   7.,   6.,   5.,
          3.,   6.,  10.,   6.,   6.,   1.,   6.,   4.,   4.,   3.,   3.,
          6.,   5.,   3.,   5.,   3.,   4.,   6.,   3.,  10.,   1.,   2.,
          8.,   4.,   1.,   3.,   1.,   3.,  10.,   7.,   2.,   4.,   4.,
          3.,   3.,   4.,   3.,   4.,   4.,   2.,   6.,   2.,   2.,   5.,
        810.]),
 array([ 14999.        ,  15999.00412371,  16999.00824742,  17999.01237113,
         18999.01649485,  19999.02061856,  20999.02474227,  21999.02886598,
         22999.03298969,  23999.0371134 ,  24999.04123711,  25999.04536082,
         26999.04948454,  27999.05360825,  28999.05773196,  29999.06185567,
         30999.06597938,  31999.07010309,  32999.0742268 ,  33999.07835052,
         34999.08247423,  35999.08659794,  36999.09072165,  37999.09484536,
         38999.09896907,  39999.10309278,  40999.10721649,  41999.11134021,
         42999.11546392,  43999.11958763,  44999.12371134,  45999.12783505,
         46999.13195876,  47999.13608247,  48999.14020619,  49999.1443299 ,
         50999.14845361,  51999.15257732,  52999.15670103,  53999.16082474,
         54999.16494845,  55999.16907216,  56999.17319588,  57999.17731959,
         58999.1814433 ,  59999.18556701,  60999.18969072,  61999.19381443,
         62999.19793814,  63999.20206186,  64999.20618557,  65999.21030928,
         66999.21443299,  67999.2185567 ,  68999.22268041,  69999.22680412,
         70999.23092784,  71999.23505155,  72999.23917526,  73999.24329897,
         74999.24742268,  75999.25154639,  76999.2556701 ,  77999.25979381,
         78999.26391753,  79999.26804124,  80999.27216495,  81999.27628866,
         82999.28041237,  83999.28453608,  84999.28865979,  85999.29278351,
         86999.29690722,  87999.30103093,  88999.30515464,  89999.30927835,
         90999.31340206,  91999.31752577,  92999.32164948,  93999.3257732 ,
         94999.32989691,  95999.33402062,  96999.33814433,  97999.34226804,
         98999.34639175,  99999.35051546, 100999.35463918, 101999.35876289,
        102999.3628866 , 103999.36701031, 104999.37113402, 105999.37525773,
        106999.37938144, 107999.38350515, 108999.38762887, 109999.39175258,
        110999.39587629, 111999.4       , 112999.40412371, 113999.40824742,
        114999.41237113, 115999.41649485, 116999.42061856, 117999.42474227,
        118999.42886598, 119999.43298969, 120999.4371134 , 121999.44123711,
        122999.44536082, 123999.44948454, 124999.45360825, 125999.45773196,
        126999.46185567, 127999.46597938, 128999.47010309, 129999.4742268 ,
        130999.47835052, 131999.48247423, 132999.48659794, 133999.49072165,
        134999.49484536, 135999.49896907, 136999.50309278, 137999.50721649,
        138999.51134021, 139999.51546392, 140999.51958763, 141999.52371134,
        142999.52783505, 143999.53195876, 144999.53608247, 145999.54020619,
        146999.5443299 , 147999.54845361, 148999.55257732, 149999.55670103,
        150999.56082474, 151999.56494845, 152999.56907216, 153999.57319588,
        154999.57731959, 155999.5814433 , 156999.58556701, 157999.58969072,
        158999.59381443, 159999.59793814, 160999.60206186, 161999.60618557,
        162999.61030928, 163999.61443299, 164999.6185567 , 165999.62268041,
        166999.62680412, 167999.63092784, 168999.63505155, 169999.63917526,
        170999.64329897, 171999.64742268, 172999.65154639, 173999.6556701 ,
        174999.65979381, 175999.66391753, 176999.66804124, 177999.67216495,
        178999.67628866, 179999.68041237, 180999.68453608, 181999.68865979,
        182999.69278351, 183999.69690722, 184999.70103093, 185999.70515464,
        186999.70927835, 187999.71340206, 188999.71752577, 189999.72164948,
        190999.7257732 , 191999.72989691, 192999.73402062, 193999.73814433,
        194999.74226804, 195999.74639175, 196999.75051546, 197999.75463918,
        198999.75876289, 199999.7628866 , 200999.76701031, 201999.77113402,
        202999.77525773, 203999.77938144, 204999.78350515, 205999.78762887,
        206999.79175258, 207999.79587629, 208999.8       , 209999.80412371,
        210999.80824742, 211999.81237113, 212999.81649485, 213999.82061856,
        214999.82474227, 215999.82886598, 216999.83298969, 217999.8371134 ,
        218999.84123711, 219999.84536082, 220999.84948454, 221999.85360825,
        222999.85773196, 223999.86185567, 224999.86597938, 225999.87010309,
        226999.8742268 , 227999.87835052, 228999.88247423, 229999.88659794,
        230999.89072165, 231999.89484536, 232999.89896907, 233999.90309278,
        234999.90721649, 235999.91134021, 236999.91546392, 237999.91958763,
        238999.92371134, 239999.92783505, 240999.93195876, 241999.93608247,
        242999.94020619, 243999.9443299 , 244999.94845361, 245999.95257732,
        246999.95670103, 247999.96082474, 248999.96494845, 249999.96907216,
        250999.97319588, 251999.97731959, 252999.9814433 , 253999.98556701,
        254999.98969072, 255999.99381443, 256999.99793814, 258000.00206186,
        259000.00618557, 260000.01030928, 261000.01443299, 262000.0185567 ,
        263000.02268041, 264000.02680412, 265000.03092784, 266000.03505155,
        267000.03917526, 268000.04329897, 269000.04742268, 270000.05154639,
        271000.0556701 , 272000.05979381, 273000.06391753, 274000.06804124,
        275000.07216495, 276000.07628866, 277000.08041237, 278000.08453608,
        279000.08865979, 280000.09278351, 281000.09690722, 282000.10103093,
        283000.10515464, 284000.10927835, 285000.11340206, 286000.11752577,
        287000.12164948, 288000.1257732 , 289000.12989691, 290000.13402062,
        291000.13814433, 292000.14226804, 293000.14639175, 294000.15051546,
        295000.15463918, 296000.15876289, 297000.1628866 , 298000.16701031,
        299000.17113402, 300000.17525773, 301000.17938144, 302000.18350515,
        303000.18762887, 304000.19175258, 305000.19587629, 306000.2       ,
        307000.20412371, 308000.20824742, 309000.21237113, 310000.21649485,
        311000.22061856, 312000.22474227, 313000.22886598, 314000.23298969,
        315000.2371134 , 316000.24123711, 317000.24536082, 318000.24948454,
        319000.25360825, 320000.25773196, 321000.26185567, 322000.26597938,
        323000.27010309, 324000.2742268 , 325000.27835052, 326000.28247423,
        327000.28659794, 328000.29072165, 329000.29484536, 330000.29896907,
        331000.30309278, 332000.30721649, 333000.31134021, 334000.31546392,
        335000.31958763, 336000.32371134, 337000.32783505, 338000.33195876,
        339000.33608247, 340000.34020619, 341000.3443299 , 342000.34845361,
        343000.35257732, 344000.35670103, 345000.36082474, 346000.36494845,
        347000.36907216, 348000.37319588, 349000.37731959, 350000.3814433 ,
        351000.38556701, 352000.38969072, 353000.39381443, 354000.39793814,
        355000.40206186, 356000.40618557, 357000.41030928, 358000.41443299,
        359000.4185567 , 360000.42268041, 361000.42680412, 362000.43092784,
        363000.43505155, 364000.43917526, 365000.44329897, 366000.44742268,
        367000.45154639, 368000.4556701 , 369000.45979381, 370000.46391753,
        371000.46804124, 372000.47216495, 373000.47628866, 374000.48041237,
        375000.48453608, 376000.48865979, 377000.49278351, 378000.49690722,
        379000.50103093, 380000.50515464, 381000.50927835, 382000.51340206,
        383000.51752577, 384000.52164948, 385000.5257732 , 386000.52989691,
        387000.53402062, 388000.53814433, 389000.54226804, 390000.54639175,
        391000.55051546, 392000.55463918, 393000.55876289, 394000.5628866 ,
        395000.56701031, 396000.57113402, 397000.57525773, 398000.57938144,
        399000.58350515, 400000.58762887, 401000.59175258, 402000.59587629,
        403000.6       , 404000.60412371, 405000.60824742, 406000.61237113,
        407000.61649485, 408000.62061856, 409000.62474227, 410000.62886598,
        411000.63298969, 412000.6371134 , 413000.64123711, 414000.64536082,
        415000.64948454, 416000.65360825, 417000.65773196, 418000.66185567,
        419000.66597938, 420000.67010309, 421000.6742268 , 422000.67835052,
        423000.68247423, 424000.68659794, 425000.69072165, 426000.69484536,
        427000.69896907, 428000.70309278, 429000.70721649, 430000.71134021,
        431000.71546392, 432000.71958763, 433000.72371134, 434000.72783505,
        435000.73195876, 436000.73608247, 437000.74020619, 438000.7443299 ,
        439000.74845361, 440000.75257732, 441000.75670103, 442000.76082474,
        443000.76494845, 444000.76907216, 445000.77319588, 446000.77731959,
        447000.7814433 , 448000.78556701, 449000.78969072, 450000.79381443,
        451000.79793814, 452000.80206186, 453000.80618557, 454000.81030928,
        455000.81443299, 456000.8185567 , 457000.82268041, 458000.82680412,
        459000.83092784, 460000.83505155, 461000.83917526, 462000.84329897,
        463000.84742268, 464000.85154639, 465000.8556701 , 466000.85979381,
        467000.86391753, 468000.86804124, 469000.87216495, 470000.87628866,
        471000.88041237, 472000.88453608, 473000.88865979, 474000.89278351,
        475000.89690722, 476000.90103093, 477000.90515464, 478000.90927835,
        479000.91340206, 480000.91752577, 481000.92164948, 482000.9257732 ,
        483000.92989691, 484000.93402062, 485000.93814433, 486000.94226804,
        487000.94639175, 488000.95051546, 489000.95463918, 490000.95876289,
        491000.9628866 , 492000.96701031, 493000.97113402, 494000.97525773,
        495000.97938144, 496000.98350515, 497000.98762887, 498000.99175258,
        499000.99587629, 500001.        ]),
 &lt;BarContainer object of 485 artists&gt;)
</code></pre></div></div>

<p><img src="output_109_1.png" alt="png" /></p>

<p>Check docs on how to detect picks :</p>
<ul>
  <li>
    <p>Finding peaks in the histograms of the variables : https://www.kaggle.com/simongrest/finding-peaks-in-the-histograms-of-the-variables</p>
  </li>
  <li>
    <p>Peak-finding algorithm for Python/SciPy : https://stackoverflow.com/questions/1713335/peak-finding-algorithm-for-python-scipy</p>
  </li>
</ul>

<h2 id="experimenting-with-attribute-combinations">Experimenting with Attribute Combinations</h2>

<ul>
  <li>We identified a <code class="language-plaintext highlighter-rouge">few data quirks</code> that we may want to clean up
before feeding the data to a Machine Learning algorithm,</li>
  <li>We found interesting <code class="language-plaintext highlighter-rouge">correlations between attributes</code>, in particular with <code class="language-plaintext highlighter-rouge">the target attribute</code>.</li>
  <li>We also noticed that some attributes have a <code class="language-plaintext highlighter-rouge">tail-heavy distribution</code>, so you may want to transform
them (e.g., by computing their logarithm).</li>
  <li>One last thing we may want to do before preparing the data for Machine Learning
algorithms is to <code class="language-plaintext highlighter-rouge">try out various attribute combinations</code> :
For example, the <code class="language-plaintext highlighter-rouge">total number of rooms</code> in a district is not very useful if we donâ€™t know how many <code class="language-plaintext highlighter-rouge">households</code>
there are. What we really want is <code class="language-plaintext highlighter-rouge">the number of rooms per household</code>.
Similarly, the <code class="language-plaintext highlighter-rouge">total number of bedrooms</code> by itself is not very useful: you probably want to compare
it to <code class="language-plaintext highlighter-rouge">the number of rooms</code>. 
And <code class="language-plaintext highlighter-rouge">the population per household</code> also seems like an interesting attribute combination to look at. Letâ€™s create these new attributes:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># We can see that some attributes are very linked to each others
</span><span class="n">housing</span><span class="p">[[</span><span class="s">'total_rooms'</span><span class="p">,</span><span class="s">'total_bedrooms'</span><span class="p">,</span><span class="s">'households'</span><span class="p">,</span><span class="s">'population'</span> <span class="p">]].</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>households</th>
      <th>population</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>total_rooms</th>
      <td>1.000000</td>
      <td>0.930380</td>
      <td>0.918484</td>
      <td>0.857126</td>
    </tr>
    <tr>
      <th>total_bedrooms</th>
      <td>0.930380</td>
      <td>1.000000</td>
      <td>0.979728</td>
      <td>0.877747</td>
    </tr>
    <tr>
      <th>households</th>
      <td>0.918484</td>
      <td>0.979728</td>
      <td>1.000000</td>
      <td>0.907222</td>
    </tr>
    <tr>
      <th>population</th>
      <td>0.857126</td>
      <td>0.877747</td>
      <td>0.907222</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>To highlight the matrix correlation, we can use <code class="language-plaintext highlighter-rouge">heatmap</code> from <code class="language-plaintext highlighter-rouge">seaborn</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="n">cor</span><span class="o">=</span> <span class="n">housing</span><span class="p">[[</span><span class="s">'total_rooms'</span><span class="p">,</span><span class="s">'total_bedrooms'</span><span class="p">,</span><span class="s">'households'</span><span class="p">,</span><span class="s">'population'</span> <span class="p">]].</span><span class="n">corr</span><span class="p">()</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cor</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'Blues'</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;AxesSubplot:&gt;
</code></pre></div></div>

<p><img src="output_115_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">[</span><span class="s">"rooms_per_household"</span><span class="p">]</span> <span class="o">=</span> <span class="n">housing</span><span class="p">[</span><span class="s">"total_rooms"</span><span class="p">]</span><span class="o">/</span><span class="n">housing</span><span class="p">[</span><span class="s">"households"</span><span class="p">]</span>
<span class="n">housing</span><span class="p">[</span><span class="s">"bedrooms_per_room"</span><span class="p">]</span> <span class="o">=</span> <span class="n">housing</span><span class="p">[</span><span class="s">"total_bedrooms"</span><span class="p">]</span><span class="o">/</span><span class="n">housing</span><span class="p">[</span><span class="s">"total_rooms"</span><span class="p">]</span>
<span class="n">housing</span><span class="p">[</span><span class="s">"population_per_household"</span><span class="p">]</span><span class="o">=</span><span class="n">housing</span><span class="p">[</span><span class="s">"population"</span><span class="p">]</span><span class="o">/</span><span class="n">housing</span><span class="p">[</span><span class="s">"households"</span><span class="p">]</span> <span class="c1"># nbre of person per houshold
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">[</span><span class="s">"bedrooms_per_room"</span><span class="p">].</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>count    20433.000000
mean         0.213039
std          0.057983
min          0.100000
25%          0.175427
50%          0.203162
75%          0.239821
max          1.000000
Name: bedrooms_per_room, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># on average, we have 21 bedrooms for 100 rooms
</span><span class="kn">from</span> <span class="nn">fractions</span> <span class="kn">import</span> <span class="n">Fraction</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">Fraction</span><span class="p">(</span><span class="mf">0.21</span><span class="p">).</span><span class="n">limit_denominator</span><span class="p">()</span>
<span class="n">z</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fraction(21, 100)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">housing</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">corr_matrix</span><span class="p">[</span><span class="s">'median_house_value'</span><span class="p">].</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>median_house_value          1.000000
median_income               0.688075
rooms_per_household         0.151948
total_rooms                 0.134153
housing_median_age          0.105623
households                  0.065843
total_bedrooms              0.049686
population_per_household   -0.023737
population                 -0.024650
longitude                  -0.045967
latitude                   -0.144160
bedrooms_per_room          -0.255880
Name: median_house_value, dtype: float64
</code></pre></div></div>

<p>The new <code class="language-plaintext highlighter-rouge">bedrooms_per_room attribute</code> is much more correlated (0.25)with the <code class="language-plaintext highlighter-rouge">median house value</code> than <code class="language-plaintext highlighter-rouge">the total number of rooms</code>(0.13) or bedrooms (0.04) :</p>
<ul>
  <li>Apparently houses with a lower bedroom/room ratio tend to be more expensive.</li>
  <li>The <code class="language-plaintext highlighter-rouge">number of rooms per household</code> is also more informative than <code class="language-plaintext highlighter-rouge">the total number of rooms</code> in a districtâ€”obviously the larger the houses, the more expensive they are.</li>
</ul>

<h1 id="prepare-the-data-for-machine-learning-algorithms">Prepare the Data for Machine Learning Algorithms</h1>

<ul>
  <li>letâ€™s revert to a <code class="language-plaintext highlighter-rouge">clean training set</code> (by copying strat_train_set once again).</li>
  <li>Letâ€™s also <code class="language-plaintext highlighter-rouge">separate the predictors</code> and <code class="language-plaintext highlighter-rouge">the labels</code>, since we donâ€™t necessarily want to apply the same transformations to the predictors and the target values.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># drop() creates a copy of the data and does not affect strat_train_set
</span><span class="n">housing</span> <span class="o">=</span> <span class="n">strat_train_set</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">"median_house_value"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
<span class="n">housing_labels</span> <span class="o">=</span> <span class="n">strat_train_set</span><span class="p">[</span><span class="s">"median_house_value"</span><span class="p">].</span><span class="n">copy</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span> <span class="o">=</span> <span class="n">strat_train_set</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'median_house_value'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">housing_labels</span> <span class="o">=</span> <span class="n">strat_train_set</span><span class="p">[</span><span class="s">'median_house_value'</span><span class="p">].</span><span class="n">copy</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="data-cleaning">Data Cleaning</h2>

<p>For<code class="language-plaintext highlighter-rouge">missing values</code> (like for <code class="language-plaintext highlighter-rouge">total_bedrooms</code>), we have three options:</p>
<ol>
  <li>Get rid of the corresponding districts.</li>
  <li>Get rid of the whole attribute.</li>
  <li>Set the values to some value (zero, the mean, the median, etc.)</li>
</ol>

<p>We can accomplish these easily using DataFrameâ€™s dropna(), drop(), and fillna()</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">[</span><span class="s">'total_bedrooms'</span><span class="p">].</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>count    16354.000000
mean       534.914639
std        412.665649
min          2.000000
25%        295.000000
50%        433.000000
75%        644.000000
max       6210.000000
Name: total_bedrooms, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># in bar chart, NanN's are filled with 0's
</span><span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">housing</span><span class="p">[</span><span class="s">'total_bedrooms'</span><span class="p">]</span>
        <span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="nb">int</span> <span class="p">((</span><span class="mf">6210.000000</span> <span class="o">-</span> <span class="mf">2.000000</span> <span class="p">)</span><span class="o">/</span><span class="mi">500</span><span class="p">)</span>
        <span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'blue'</span>
        <span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s">'black'</span> 
        <span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(array([1.0221e+04, 4.7670e+03, 9.1400e+02, 2.6100e+02, 9.9000e+01,
        5.1000e+01, 1.7000e+01, 1.1000e+01, 7.0000e+00, 3.0000e+00,
        2.0000e+00, 1.0000e+00]),
 array([2.00000000e+00, 5.19333333e+02, 1.03666667e+03, 1.55400000e+03,
        2.07133333e+03, 2.58866667e+03, 3.10600000e+03, 3.62333333e+03,
        4.14066667e+03, 4.65800000e+03, 5.17533333e+03, 5.69266667e+03,
        6.21000000e+03]),
 &lt;BarContainer object of 12 artists&gt;)
</code></pre></div></div>

<p><img src="output_128_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># to count the number of Nan's
</span><span class="n">housing</span><span class="p">[</span><span class="s">'total_bedrooms'</span><span class="p">].</span><span class="n">isna</span><span class="p">().</span><span class="nb">sum</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>158
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">.</span><span class="n">isna</span><span class="p">().</span><span class="nb">sum</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>longitude               0
latitude                0
housing_median_age      0
total_rooms             0
total_bedrooms        158
population              0
households              0
median_income           0
ocean_proximity         0
income_cat              0
dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># option 1 : Get rid of the corresponding districts
</span><span class="n">housing</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span> <span class="o">=</span> <span class="p">[</span><span class="s">'total_bedrooms'</span><span class="p">])</span> <span class="c1"># drop from 16512 to 16354 using len()
</span>
<span class="c1"># option 2 : Get rid of the whole attribute
</span><span class="n">housing</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'total_bedrooms'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># option 3 : Set the values to some value (zero, the mean, the median, etc.)
</span><span class="n">median</span> <span class="o">=</span> <span class="n">housing</span><span class="p">[</span><span class="s">'total_bedrooms'</span><span class="p">].</span><span class="n">median</span><span class="p">()</span>
<span class="n">housing</span><span class="p">[</span><span class="s">'total_bedrooms'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">median</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>ocean_proximity</th>
      <th>income_cat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12655</th>
      <td>-121.46</td>
      <td>38.52</td>
      <td>29.0</td>
      <td>3873.0</td>
      <td>2237.0</td>
      <td>706.0</td>
      <td>2.1736</td>
      <td>INLAND</td>
      <td>2</td>
    </tr>
    <tr>
      <th>15502</th>
      <td>-117.23</td>
      <td>33.09</td>
      <td>7.0</td>
      <td>5320.0</td>
      <td>2015.0</td>
      <td>768.0</td>
      <td>6.3373</td>
      <td>NEAR OCEAN</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2908</th>
      <td>-119.04</td>
      <td>35.37</td>
      <td>44.0</td>
      <td>1618.0</td>
      <td>667.0</td>
      <td>300.0</td>
      <td>2.8750</td>
      <td>INLAND</td>
      <td>2</td>
    </tr>
    <tr>
      <th>14053</th>
      <td>-117.13</td>
      <td>32.75</td>
      <td>24.0</td>
      <td>1877.0</td>
      <td>898.0</td>
      <td>483.0</td>
      <td>2.2264</td>
      <td>NEAR OCEAN</td>
      <td>2</td>
    </tr>
    <tr>
      <th>20496</th>
      <td>-118.70</td>
      <td>34.28</td>
      <td>27.0</td>
      <td>3536.0</td>
      <td>1837.0</td>
      <td>580.0</td>
      <td>4.4964</td>
      <td>&lt;1H OCEAN</td>
      <td>3</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>15174</th>
      <td>-117.07</td>
      <td>33.03</td>
      <td>14.0</td>
      <td>6665.0</td>
      <td>2026.0</td>
      <td>1001.0</td>
      <td>5.0900</td>
      <td>&lt;1H OCEAN</td>
      <td>4</td>
    </tr>
    <tr>
      <th>12661</th>
      <td>-121.42</td>
      <td>38.51</td>
      <td>15.0</td>
      <td>7901.0</td>
      <td>4769.0</td>
      <td>1418.0</td>
      <td>2.8139</td>
      <td>INLAND</td>
      <td>2</td>
    </tr>
    <tr>
      <th>19263</th>
      <td>-122.72</td>
      <td>38.44</td>
      <td>48.0</td>
      <td>707.0</td>
      <td>458.0</td>
      <td>172.0</td>
      <td>3.1797</td>
      <td>&lt;1H OCEAN</td>
      <td>3</td>
    </tr>
    <tr>
      <th>19140</th>
      <td>-122.70</td>
      <td>38.31</td>
      <td>14.0</td>
      <td>3155.0</td>
      <td>1208.0</td>
      <td>501.0</td>
      <td>4.1964</td>
      <td>&lt;1H OCEAN</td>
      <td>3</td>
    </tr>
    <tr>
      <th>19773</th>
      <td>-122.14</td>
      <td>39.97</td>
      <td>27.0</td>
      <td>1079.0</td>
      <td>625.0</td>
      <td>197.0</td>
      <td>3.1319</td>
      <td>INLAND</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>16512 rows Ã— 9 columns</p>
</div>

<p>For â€˜optionâ€™ 3 : fill missings with some value, the median for example, we should :</p>
<ul>
  <li>Compute the median value on <code class="language-plaintext highlighter-rouge">the training</code> and use it to <code class="language-plaintext highlighter-rouge">fill the missing values</code> in the training set.</li>
  <li><code class="language-plaintext highlighter-rouge">Save the median value</code> that you have computed.</li>
  <li><code class="language-plaintext highlighter-rouge">Using later</code> for <code class="language-plaintext highlighter-rouge">to replace missing values</code> in the <code class="language-plaintext highlighter-rouge">test set</code> when we want to <code class="language-plaintext highlighter-rouge">evaluate our system</code></li>
  <li>Using it once the <code class="language-plaintext highlighter-rouge">system goes live</code> to <code class="language-plaintext highlighter-rouge">replace missing values in new data</code>.</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">Scikit-Learn</code> provides a handy class to take care of missing values: <code class="language-plaintext highlighter-rouge">SimpleImputer</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
</code></pre></div></div>

<p>First, you need to create a <code class="language-plaintext highlighter-rouge">SimpleImputer instance</code>, specifying that we want to replace <code class="language-plaintext highlighter-rouge">each numeric attributeâ€™s missing values</code> with <code class="language-plaintext highlighter-rouge">the median of that attribute</code> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="s">'median'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">.</span><span class="n">dtypes</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>longitude             float64
latitude              float64
housing_median_age    float64
total_rooms           float64
total_bedrooms        float64
population            float64
households            float64
median_income         float64
ocean_proximity        object
dtype: object
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># We drop the categorical variables since the median can only be computed on numerical attributes
</span><span class="n">housing_num</span> <span class="o">=</span> <span class="n">housing</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'ocean_proximity'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>Now you can <code class="language-plaintext highlighter-rouge">fit</code> the <code class="language-plaintext highlighter-rouge">imputer instance</code> to the <code class="language-plaintext highlighter-rouge">training data</code> using the <code class="language-plaintext highlighter-rouge">fit()</code> method</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imputer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">housing_num</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SimpleImputer(strategy='median')
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">imputer</code> has <code class="language-plaintext highlighter-rouge">simply computed the median</code> of each <code class="language-plaintext highlighter-rouge">attribute</code> and stored the result
in its <code class="language-plaintext highlighter-rouge">statistics_</code> instance variable. We apply the <code class="language-plaintext highlighter-rouge">imputer to all the numerical attributes</code> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imputer</span><span class="p">.</span><span class="n">statistics_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([-118.51   ,   34.26   ,   29.     , 2119.     ,  433.     ,
       1164.     ,  408.     ,    3.54155])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_num</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',
       'total_bedrooms', 'population', 'households', 'median_income'],
      dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># equivalant to imputer.statistics_ : we have the median for each numeric variable
</span><span class="n">housing_num</span><span class="p">.</span><span class="n">median</span><span class="p">().</span><span class="n">values</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([-118.51   ,   34.26   ,   29.     , 2119.     ,  433.     ,
       1164.     ,  408.     ,    3.54155])
</code></pre></div></div>

<p>Now we can use this <code class="language-plaintext highlighter-rouge">trained</code> imputer to <code class="language-plaintext highlighter-rouge">transform the training set</code> by <code class="language-plaintext highlighter-rouge">replacing</code>
missing values with the <code class="language-plaintext highlighter-rouge">learned medians</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># The result is a plain NumPy array containing the transformed features. 
</span><span class="n">X</span> <span class="o">=</span> <span class="n">imputer</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">housing_num</span><span class="p">)</span>


<span class="c1">#If you want to put it back into a pandas DataFrame, itâ€™s simple:
</span><span class="n">housing_tr</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">housing_num</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span>
                            <span class="n">index</span><span class="o">=</span><span class="n">housing_num</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>
</code></pre></div></div>

<p>Alternative method to <code class="language-plaintext highlighter-rouge">fit()</code> and <code class="language-plaintext highlighter-rouge">transform()</code> method is using directy <code class="language-plaintext highlighter-rouge">fit_transform()</code> method</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">imputer</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">housing_num</span><span class="p">)</span>

<span class="n">housing_tr</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="n">X</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">housing_num</span><span class="p">.</span><span class="n">columns</span>
                         <span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">housing_num</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">housing_tr</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12655</th>
      <td>-121.46</td>
      <td>38.52</td>
      <td>29.0</td>
      <td>3873.0</td>
      <td>797.0</td>
      <td>2237.0</td>
      <td>706.0</td>
      <td>2.1736</td>
    </tr>
    <tr>
      <th>15502</th>
      <td>-117.23</td>
      <td>33.09</td>
      <td>7.0</td>
      <td>5320.0</td>
      <td>855.0</td>
      <td>2015.0</td>
      <td>768.0</td>
      <td>6.3373</td>
    </tr>
    <tr>
      <th>2908</th>
      <td>-119.04</td>
      <td>35.37</td>
      <td>44.0</td>
      <td>1618.0</td>
      <td>310.0</td>
      <td>667.0</td>
      <td>300.0</td>
      <td>2.8750</td>
    </tr>
    <tr>
      <th>14053</th>
      <td>-117.13</td>
      <td>32.75</td>
      <td>24.0</td>
      <td>1877.0</td>
      <td>519.0</td>
      <td>898.0</td>
      <td>483.0</td>
      <td>2.2264</td>
    </tr>
    <tr>
      <th>20496</th>
      <td>-118.70</td>
      <td>34.28</td>
      <td>27.0</td>
      <td>3536.0</td>
      <td>646.0</td>
      <td>1837.0</td>
      <td>580.0</td>
      <td>4.4964</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>15174</th>
      <td>-117.07</td>
      <td>33.03</td>
      <td>14.0</td>
      <td>6665.0</td>
      <td>1231.0</td>
      <td>2026.0</td>
      <td>1001.0</td>
      <td>5.0900</td>
    </tr>
    <tr>
      <th>12661</th>
      <td>-121.42</td>
      <td>38.51</td>
      <td>15.0</td>
      <td>7901.0</td>
      <td>1422.0</td>
      <td>4769.0</td>
      <td>1418.0</td>
      <td>2.8139</td>
    </tr>
    <tr>
      <th>19263</th>
      <td>-122.72</td>
      <td>38.44</td>
      <td>48.0</td>
      <td>707.0</td>
      <td>166.0</td>
      <td>458.0</td>
      <td>172.0</td>
      <td>3.1797</td>
    </tr>
    <tr>
      <th>19140</th>
      <td>-122.70</td>
      <td>38.31</td>
      <td>14.0</td>
      <td>3155.0</td>
      <td>580.0</td>
      <td>1208.0</td>
      <td>501.0</td>
      <td>4.1964</td>
    </tr>
    <tr>
      <th>19773</th>
      <td>-122.14</td>
      <td>39.97</td>
      <td>27.0</td>
      <td>1079.0</td>
      <td>222.0</td>
      <td>625.0</td>
      <td>197.0</td>
      <td>3.1319</td>
    </tr>
  </tbody>
</table>
<p>16512 rows Ã— 8 columns</p>
</div>

<h2 id="handling-text-and-categorical-attributes">Handling Text and Categorical Attributes</h2>

<p>So far we have only dealt with <code class="language-plaintext highlighter-rouge">numerical attributes</code>, but now letâ€™s look at <code class="language-plaintext highlighter-rouge">text attributes</code>. 
In this dataset, there is just one: the <code class="language-plaintext highlighter-rouge">ocean_proximity</code> attribute. 
Letâ€™s look at its value for the first 10 instances:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_cat</span> <span class="o">=</span> <span class="n">housing</span><span class="p">[[</span><span class="s">'ocean_proximity'</span><span class="p">]]</span>
<span class="n">housing_cat</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">housing_cat</span><span class="p">.</span><span class="n">nunique</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ocean_proximity    5
dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">[</span><span class="s">'ocean_proximity'</span><span class="p">].</span><span class="n">unique</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array(['INLAND', 'NEAR OCEAN', '&lt;1H OCEAN', 'NEAR BAY', 'ISLAND'],
      dtype=object)
</code></pre></div></div>

<p>Itâ€™s <code class="language-plaintext highlighter-rouge">not arbitrary text</code>: there are a <code class="language-plaintext highlighter-rouge">limited number of possible values</code>, each of which represents a <code class="language-plaintext highlighter-rouge">category</code>. So this attribute is a <code class="language-plaintext highlighter-rouge">categorical attribute</code>. 
Most Machine Learning algorithms prefer to work with <code class="language-plaintext highlighter-rouge">numbers</code>, so <code class="language-plaintext highlighter-rouge">letâ€™s convert these categories from
text to numbers</code>.
For this, we can use <code class="language-plaintext highlighter-rouge">Scikit-Learnâ€™s OrdinalEncoder</code> class :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OrdinalEncoder</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ordinal_encoder</span> <span class="o">=</span> <span class="n">OrdinalEncoder</span><span class="p">()</span>
<span class="n">housing_cat_encoded</span> <span class="o">=</span> <span class="n">ordinal_encoder</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">housing_cat</span><span class="p">)</span> <span class="c1"># categorical dataframe
</span><span class="n">housing_cat_encoded</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[1.],
       [4.],
       [1.],
       [4.],
       [0.],
       [3.],
       [0.],
       [0.],
       [0.],
       [0.]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_cat_encoded</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(16512, 1)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># we  can get the list of categories using the categories_ instance variable. It is a list containing a 1D array 
</span>   <span class="c1">#of categories for each categorical attribute
</span>    
<span class="n">ordinal_encoder</span><span class="p">.</span><span class="n">categories_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[array(['&lt;1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],
       dtype=object)]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">housing_cat_encoded</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0., 1., 2., 3., 4.])
</code></pre></div></div>

<p>One issue with this representation is that ML algorithms ( OrdinaEncoder) <code class="language-plaintext highlighter-rouge">will assume that two nearby
values</code> are <code class="language-plaintext highlighter-rouge">more similar</code> than <code class="language-plaintext highlighter-rouge">two distant values</code>. This may be fine in some cases (e.g., for <code class="language-plaintext highlighter-rouge">ordered categories</code> such as â€œbad,â€ â€œaverage,â€ â€œgood,â€ and â€œexcellentâ€) : <code class="language-plaintext highlighter-rouge">ordinal encoding for categorical variables that have a natural rank ordering</code>
but it is obviously not the case for the <code class="language-plaintext highlighter-rouge">ocean_proximity column</code> (for example, <code class="language-plaintext highlighter-rouge">categories 0 and 4 are clearly more similar</code> than categories 0 and 1).</p>

<p>To fix this issue, a common solution is to create <code class="language-plaintext highlighter-rouge">one binary attribute per category</code>: one attribute equal to 1 when the category is â€œ&lt;1H OCEANâ€ (and 0 otherwise), another attribute equal to 1 when the category is â€œINLANDâ€ (and 0 otherwise), and so on. This is called <code class="language-plaintext highlighter-rouge">one-hot encoding</code>.
The <code class="language-plaintext highlighter-rouge">new attributes</code> are sometimes called <code class="language-plaintext highlighter-rouge">dummy attributes</code>.
Scikit-Learn provides a <code class="language-plaintext highlighter-rouge">OneHotEncoder class</code> to convert <code class="language-plaintext highlighter-rouge">categorical values</code> into <code class="language-plaintext highlighter-rouge">one-hot vectors</code></p>

<p>See this blogpost : https://machinelearningmastery.com/one-hot-encoding-for-categorical-data/</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="n">cat_encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>
<span class="n">housing_cat_1hot</span> <span class="o">=</span> <span class="n">cat_encoder</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">housing_cat</span><span class="p">)</span>
<span class="n">housing_cat_1hot</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;16512x5 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
	with 16512 stored elements in Compressed Sparse Row format&gt;
</code></pre></div></div>

<p>Notice that the <code class="language-plaintext highlighter-rouge">output is a SciPy sparse matrix</code>, instead of a NumPy array. 
This is <code class="language-plaintext highlighter-rouge">very useful when you have categorical attributes with thousands of categories</code>.
After onehot encoding, we get a matrix with thousands of columns, and the matrix is full of 0s
except for a single 1 per row. Using up tons of memory mostly to store zeros would
be very wasteful, so instead <code class="language-plaintext highlighter-rouge">a sparse matrix only stores the location of the nonzero
elements</code>.
we can use it mostly like a normal 2D array,but if we really want to convert it to a (dense) NumPy array, we call the <code class="language-plaintext highlighter-rouge">toarray()</code> method:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_cat_1hot</span><span class="p">.</span><span class="n">toarray</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[0., 1., 0., 0., 0.],
       [0., 0., 0., 0., 1.],
       [0., 1., 0., 0., 0.],
       ...,
       [1., 0., 0., 0., 0.],
       [1., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0.]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_cat</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12655</th>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>15502</th>
      <td>NEAR OCEAN</td>
    </tr>
    <tr>
      <th>2908</th>
      <td>INLAND</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># to get the list of categories
</span><span class="n">cat_encoder</span><span class="p">.</span><span class="n">categories_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[array(['&lt;1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],
       dtype=object)]
</code></pre></div></div>

<p>If a <code class="language-plaintext highlighter-rouge">categorical attribute</code> has a <code class="language-plaintext highlighter-rouge">large number of possible categories</code> (e.g., country code, profession, species), then <code class="language-plaintext highlighter-rouge">one-hot encoding will result in a large number of input features</code>. This may slow down <code class="language-plaintext highlighter-rouge">training</code> and <code class="language-plaintext highlighter-rouge">degrade performance</code>.</p>

<p>If this happens, we may want to replace <code class="language-plaintext highlighter-rouge">the categorical input</code> with <code class="language-plaintext highlighter-rouge">useful numerical features</code>
related to the categories: for example, we could replace the <code class="language-plaintext highlighter-rouge">ocean_proximity feature</code> with <code class="language-plaintext highlighter-rouge">the distance to the ocean</code> (similarly, a country code could be replaced with the countryâ€™s population and GDP per capita). Alternatively, we could replace each category with a learnable, low-dimensional vector called an <code class="language-plaintext highlighter-rouge">embedding</code>.</p>

<p>Each categoryâ€™s representation would be learned during training. This is an example of <code class="language-plaintext highlighter-rouge">representation learning</code>.</p>

<h2 id="custom-transformers">Custom Transformers</h2>

<p>retun back for more details ? see blogpost : https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-the-step-by-step-guide-with-python-code-4a7d9b068156</p>

<p>and this : https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">.</span><span class="n">values</span><span class="p">[:</span> <span class="p">,</span><span class="mi">4</span><span class="p">:]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[797.0, 2237.0, 706.0, 2.1736, 'INLAND', 2],
       [855.0, 2015.0, 768.0, 6.3373, 'NEAR OCEAN', 5],
       [310.0, 667.0, 300.0, 2.875, 'INLAND', 2],
       ...,
       [166.0, 458.0, 172.0, 3.1797, '&lt;1H OCEAN', 3],
       [580.0, 1208.0, 501.0, 4.1964, '&lt;1H OCEAN', 3],
       [222.0, 625.0, 197.0, 3.1319, 'INLAND', 3]], dtype=object)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>ocean_proximity</th>
      <th>income_cat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12655</th>
      <td>-121.46</td>
      <td>38.52</td>
      <td>29.0</td>
      <td>3873.0</td>
      <td>797.0</td>
      <td>2237.0</td>
      <td>706.0</td>
      <td>2.1736</td>
      <td>INLAND</td>
      <td>2</td>
    </tr>
    <tr>
      <th>15502</th>
      <td>-117.23</td>
      <td>33.09</td>
      <td>7.0</td>
      <td>5320.0</td>
      <td>855.0</td>
      <td>2015.0</td>
      <td>768.0</td>
      <td>6.3373</td>
      <td>NEAR OCEAN</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2908</th>
      <td>-119.04</td>
      <td>35.37</td>
      <td>44.0</td>
      <td>1618.0</td>
      <td>310.0</td>
      <td>667.0</td>
      <td>300.0</td>
      <td>2.8750</td>
      <td>INLAND</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>

<span class="n">rooms_ix</span><span class="p">,</span> <span class="n">bedrooms_ix</span><span class="p">,</span> <span class="n">population_ix</span><span class="p">,</span> <span class="n">households_ix</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span>

<span class="k">class</span> <span class="nc">CombinedAttributesAdder</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">add_bedrooms_per_room</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span> <span class="c1"># no *args or **kargs
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">add_bedrooms_per_room</span> <span class="o">=</span> <span class="n">add_bedrooms_per_room</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span> <span class="c1"># nothing else to do
</span>    
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">rooms_per_household</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">rooms_ix</span><span class="p">]</span> <span class="o">/</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">households_ix</span><span class="p">]</span>
        <span class="n">population_per_household</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">population_ix</span><span class="p">]</span> <span class="o">/</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">households_ix</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">add_bedrooms_per_room</span><span class="p">:</span>
            <span class="n">bedrooms_per_room</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">bedrooms_ix</span><span class="p">]</span> <span class="o">/</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">rooms_ix</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">rooms_per_household</span><span class="p">,</span> <span class="n">population_per_household</span><span class="p">,</span>
                            <span class="n">bedrooms_per_room</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">rooms_per_household</span><span class="p">,</span> <span class="n">population_per_household</span><span class="p">]</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">attr_adder</span> <span class="o">=</span> <span class="n">CombinedAttributesAdder</span><span class="p">(</span><span class="n">add_bedrooms_per_room</span><span class="o">=</span><span class="bp">False</span> <span class="p">)</span>
<span class="n">housing_extra_attribs</span> <span class="o">=</span> <span class="n">attr_adder</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">housing</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_extra_attribs</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[-121.46, 38.52, 29.0, ..., 2, 5.485835694050992,
        3.168555240793201],
       [-117.23, 33.09, 7.0, ..., 5, 6.927083333333333,
        2.6236979166666665],
       [-119.04, 35.37, 44.0, ..., 2, 5.3933333333333335,
        2.223333333333333],
       ...,
       [-122.72, 38.44, 48.0, ..., 3, 4.1104651162790695,
        2.6627906976744184],
       [-122.7, 38.31, 14.0, ..., 3, 6.297405189620759,
        2.411177644710579],
       [-122.14, 39.97, 27.0, ..., 3, 5.477157360406092,
        3.1725888324873095]], dtype=object)
</code></pre></div></div>

<h2 id="feature-scaling">Feature Scaling</h2>

<p>One of the most important transformations you need to apply to your data is <code class="language-plaintext highlighter-rouge">feature scaling</code>. With few exceptions, <code class="language-plaintext highlighter-rouge">Machine Learning algorithms</code> donâ€™t perform well when <code class="language-plaintext highlighter-rouge">the input numerical attributes</code> have <code class="language-plaintext highlighter-rouge">very different scales</code> .
This is the case for the housing data: <code class="language-plaintext highlighter-rouge">total_rooms</code> ranges from about 6 to 39320, while <code class="language-plaintext highlighter-rouge">median_income</code> only range from 0 to 15 :</p>

<p><code class="language-plaintext highlighter-rouge">Note that scaling the target values is generally not required</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_num</span><span class="p">.</span><span class="n">describe</span><span class="p">().</span><span class="n">T</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>longitude</th>
      <td>16512.0</td>
      <td>-119.575635</td>
      <td>2.001828</td>
      <td>-124.3500</td>
      <td>-121.80000</td>
      <td>-118.51000</td>
      <td>-118.010000</td>
      <td>-114.3100</td>
    </tr>
    <tr>
      <th>latitude</th>
      <td>16512.0</td>
      <td>35.639314</td>
      <td>2.137963</td>
      <td>32.5400</td>
      <td>33.94000</td>
      <td>34.26000</td>
      <td>37.720000</td>
      <td>41.9500</td>
    </tr>
    <tr>
      <th>housing_median_age</th>
      <td>16512.0</td>
      <td>28.653404</td>
      <td>12.574819</td>
      <td>1.0000</td>
      <td>18.00000</td>
      <td>29.00000</td>
      <td>37.000000</td>
      <td>52.0000</td>
    </tr>
    <tr>
      <th>total_rooms</th>
      <td>16512.0</td>
      <td>2622.539789</td>
      <td>2138.417080</td>
      <td>6.0000</td>
      <td>1443.00000</td>
      <td>2119.00000</td>
      <td>3141.000000</td>
      <td>39320.0000</td>
    </tr>
    <tr>
      <th>total_bedrooms</th>
      <td>16512.0</td>
      <td>533.939438</td>
      <td>410.806260</td>
      <td>2.0000</td>
      <td>296.00000</td>
      <td>433.00000</td>
      <td>641.000000</td>
      <td>6210.0000</td>
    </tr>
    <tr>
      <th>population</th>
      <td>16512.0</td>
      <td>1419.687379</td>
      <td>1115.663036</td>
      <td>3.0000</td>
      <td>784.00000</td>
      <td>1164.00000</td>
      <td>1719.000000</td>
      <td>35682.0000</td>
    </tr>
    <tr>
      <th>households</th>
      <td>16512.0</td>
      <td>497.011810</td>
      <td>375.696156</td>
      <td>2.0000</td>
      <td>279.00000</td>
      <td>408.00000</td>
      <td>602.000000</td>
      <td>5358.0000</td>
    </tr>
    <tr>
      <th>median_income</th>
      <td>16512.0</td>
      <td>3.875884</td>
      <td>1.904931</td>
      <td>0.4999</td>
      <td>2.56695</td>
      <td>3.54155</td>
      <td>4.745325</td>
      <td>15.0001</td>
    </tr>
  </tbody>
</table>
</div>

<p>There are two common ways to get all attributes to have the same scale:</p>
<ul>
  <li>
    <p>min-max scaling : ranging from <code class="language-plaintext highlighter-rouge">0 to 1</code>. Scikit-Learn provides a transformer called <code class="language-plaintext highlighter-rouge">MinMaxScaler</code> for this. It has a <code class="language-plaintext highlighter-rouge">feature_range</code> hyperparameter that lets you change the range if, for some reason, you donâ€™t want 0â€“1 : https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html</p>

    <p><img src="attachment:image.png" alt="image.png" /></p>
  </li>
  <li>
    <p>Standardization : returns has <code class="language-plaintext highlighter-rouge">unit variance</code> and unlike min-max scaling, standardization <code class="language-plaintext highlighter-rouge">does not bound values to a specific range</code>, which may be a problem for some algorithms (e.g., <code class="language-plaintext highlighter-rouge">neural networks often expect an input value ranging from 0 to 1</code>).However, standardization is <code class="language-plaintext highlighter-rouge">much less affected by outliers</code>.
Scikit-Learn provides a transformer called <code class="language-plaintext highlighter-rouge">StandardScaler</code> for standardization : https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html</p>

    <p><img src="attachment:image-2.png" alt="image-2.png" /></p>
  </li>
</ul>

<h1 id="transformation-pipelines">Transformation Pipelines</h1>

<p>As we can see, there are many data transformation steps that need to be executed in the right order. Fortunately, <code class="language-plaintext highlighter-rouge">Scikit-Learn</code> provides the <code class="language-plaintext highlighter-rouge">Pipeline class</code> to help with such sequences of transformations.</p>

<p>Here is a <code class="language-plaintext highlighter-rouge">small pipeline</code> for the <code class="language-plaintext highlighter-rouge">numerical attributes</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span><span class="n">MinMaxScaler</span>
<span class="c1"># plus the class add attribure that we created 
</span></code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">Pipeline constructor</code> takes a list of <code class="language-plaintext highlighter-rouge">name/estimator pairs</code> defining a sequence of
steps. All but the last estimator <code class="language-plaintext highlighter-rouge">must be transformers</code> (i.e., they must have a fit_transform() method).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This pipeline is for numeric pipeline, we call is num_pipeline
</span><span class="n">num_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s">'imputer'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="s">'median'</span><span class="p">)),</span>
    <span class="c1">#('attribs_adder', CombinedAttributesAdder()),
</span>    <span class="p">(</span><span class="s">'std_scaler'</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">())</span>
    
    
<span class="p">])</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_num_tr</span> <span class="o">=</span> <span class="n">num_pipeline</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">housing_num</span><span class="p">)</span>

</code></pre></div></div>

<p>So far, we have handled <code class="language-plaintext highlighter-rouge">the categorical columns and the numerical columns separately</code>.
It would be more convenient to have a single transformer able to handle all columns,
applying the appropriate transformations to each column. 
In version 0.20, Scikit-Learn introduced the <code class="language-plaintext highlighter-rouge">ColumnTransformer</code> for this purpose, and the good news is that it works great with pandas DataFrames. Letâ€™s use it to apply all the transformations to the housing data:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_attribs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">housing_num</span><span class="p">)</span>
<span class="n">cat_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s">'ocean_proximity'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">full_pipeline</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">([</span>
    <span class="p">(</span><span class="s">'num'</span><span class="p">,</span> <span class="n">num_pipeline</span><span class="p">,</span> <span class="n">num_attribs</span><span class="p">),</span>
    <span class="p">(</span><span class="s">'cat'</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(),</span> <span class="n">cat_attribs</span><span class="p">)</span>
<span class="p">]</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_prepared</span> <span class="o">=</span> <span class="n">full_pipeline</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">housing</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_prepared</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[-0.94135046,  1.34743822,  0.02756357, ...,  0.        ,
         0.        ,  0.        ],
       [ 1.17178212, -1.19243966, -1.72201763, ...,  0.        ,
         0.        ,  1.        ],
       [ 0.26758118, -0.1259716 ,  1.22045984, ...,  0.        ,
         0.        ,  0.        ],
       ...,
       [-1.5707942 ,  1.31001828,  1.53856552, ...,  0.        ,
         0.        ,  0.        ],
       [-1.56080303,  1.2492109 , -1.1653327 , ...,  0.        ,
         0.        ,  0.        ],
       [-1.28105026,  2.02567448, -0.13148926, ...,  0.        ,
         0.        ,  0.        ]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_prepared</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(13,)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_prepared</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(16512, 13)
</code></pre></div></div>

<p>to read carefully for later :</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>First we import the ColumnTransformer class, next we get the list of numerical column names and the list of categorical column names, and then we construct a Colum nTransformer. The constructor requires a list of tuples, where each tuple contains a name,22 a transformer, and a list of names (or indices) of columns that the transformer should be applied to. In this example, we specify that the numerical columns should be transformed using the num_pipeline that we defined earlier, and the categorical columns should be transformed using a OneHotEncoder. Finally, we apply this ColumnTransformer to the housing data: it applies each transformer to the appropriate columns and concatenates the outputs along the second axis (the transformers must return the same number of rows). Note that the OneHotEncoder returns a sparse matrix, while the num_pipeline returns a dense matrix. When there is such a mix of sparse and dense matrices, the Colum nTransformer estimates the density of the final matrix (i.e., the ratio of nonzero cells), and it returns a sparse matrix if the density is lower than a given threshold (by default, sparse_threshold=0.3). In this example, it returns a dense matrix. And thatâ€™s it! We have a preprocessing pipeline that takes the full housing data and applies the appropriate transformations to each column. Instead of using a transformer, you can specify the string "drop" if you want the columns to be dropped, or you can specify "pass through" if you want the columns to be left untouched. By default, the remaining columns (i.e., the ones that were not listed) will be dropped, but you can set the remainder hyperparameter to any transformer (or to "passthrough") if you want these columns to be handled differently. If you are using Scikit-Learn 0.19 or earlier, you can use a third-party library such as sklearn-pandas, or you can roll out your own custom transformer to get the same functionality as the ColumnTransformer. Alternatively, you can use the FeatureUnion class, which can apply different transformers and concatenate their outputs. But you cannot specify different columns for each transformer; they all apply to the whole data. It is possible to work around this limitation using a custom transformer for column selection (see the Jupyter notebook for an example).
</code></pre></div></div>

<p>see link : https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb</p>

<h1 id="select-and-train-a-model">Select and Train a Model</h1>

<ul>
  <li>we framed the problem</li>
  <li>we got the data and explored it</li>
  <li>we sampled a training set and a test set</li>
  <li>we wrote transformation pipelines to clean up  and prepare your data for Machine Learning algorithms automatically.</li>
</ul>

<h2 id="training-and-evaluating-on-the-training-set">Training and Evaluating on the Training Set</h2>

<p>Letâ€™s first train a Linear Regression model</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_prepared</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(16512, 13)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">lin_reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lin_reg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LinearRegression()
</code></pre></div></div>

<p>Letâ€™s try it out on a few instances from the training set:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># let's try the full preprocessing pipeline on a few training instances
</span><span class="n">some_data</span> <span class="o">=</span> <span class="n">housing</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
<span class="n">some_labels</span> <span class="o">=</span> <span class="n">housing_labels</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
<span class="n">some_data_prepared</span> <span class="o">=</span> <span class="n">full_pipeline</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">some_data</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Predictions:"</span><span class="p">,</span> <span class="n">lin_reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">some_data_prepared</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Predictions: [ 88983.14806384 305351.35385026 153334.71183453 184302.55162102
 246840.18988841]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"Labels:"</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">some_labels</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Labels: [72100.0, 279600.0, 82700.0, 112500.0, 238300.0]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">some_data_prepared</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(5, 13)
</code></pre></div></div>

<ul>
  <li>Some remarks :
    <ul>
      <li>If we encotered missing values are in the test set ? ( OneHotEncode() has a paramete : handle_unknown = â€˜ignoreâ€™)</li>
      <li>Indexing and selection data : if we want to modifiy a certain column in the dataframe, we should not proceed in this way : df[â€˜ocean_proxemity][0]= np.nan but rather copy the dataset first and then df.loc[0,â€™ocean_proxemityâ€™]=np.nan.
  Read : https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy</li>
    </ul>
  </li>
</ul>

<p>More on sklearn pipelines : https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html</p>

<ul>
  <li>The iloc indexer for Pandas Dataframe is used for <code class="language-plaintext highlighter-rouge">integer-location based indexing</code> / <code class="language-plaintext highlighter-rouge">selection by position</code>.</li>
  <li>The Pandas loc indexer can be used with DataFrames for two different use cases:
    <ul>
      <li>Selecting rows by <code class="language-plaintext highlighter-rouge">label/index</code></li>
      <li>Selecting rows with a boolean / conditional lookup</li>
    </ul>
  </li>
</ul>

<p>Read : https://www.shanelynn.ie/pandas-iloc-loc-select-rows-and-columns-dataframe/</p>

<p><img src="attachment:image.png" alt="image.png" /></p>

<p>Letâ€™s measure this regression <code class="language-plaintext highlighter-rouge">modelâ€™s RMSE</code> on the whole training set using Scikit-Learnâ€™s mean_squared_error() function :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#
</span><span class="n">housing_predictions</span> <span class="o">=</span> <span class="n">lin_reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">)</span>
<span class="n">housing_predictions</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([ 88983.14806384, 305351.35385026, 153334.71183453, 184302.55162102])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_labels</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12655     72100.0
15502    279600.0
2908      82700.0
14053    112500.0
20496    238300.0
           ...   
15174    268500.0
12661     90400.0
19263    140400.0
19140    258100.0
19773     62700.0
Name: median_house_value, Length: 16512, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#RMSE
</span><span class="n">lin_rmse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">housing_predictions</span><span class="p">,</span><span class="n">housing_labels</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="n">lin_rmse</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>69050.56219504567
</code></pre></div></div>

<p>Most districtsâ€™ median_housing_values range between <code class="language-plaintext highlighter-rouge">$120,000 and $265,000</code>, so a typical prediction error of
$69,050 is not very satisfying:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">housing_labels</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>count     16512.000000
mean     207005.322372
std      115701.297250
min       14999.000000
25%      119800.000000
50%      179500.000000
75%      263900.000000
max      500001.000000
Name: median_house_value, dtype: float64
</code></pre></div></div>

<p>This is an example of a <code class="language-plaintext highlighter-rouge">model underfitting</code> the training data : When this happens it can mean that <code class="language-plaintext highlighter-rouge">the features do not provide enough information</code> to make good predictions, or that <code class="language-plaintext highlighter-rouge">the model is not powerful enough</code>. As
we saw in the previous chapter, the main ways to fix underfitting are <code class="language-plaintext highlighter-rouge">to select a more powerful model</code>, to feed the training algorithm with better features, or <code class="language-plaintext highlighter-rouge">to reduce the constraints on the model</code>.</p>

<ul>
  <li>Letâ€™s train a DecisionTreeRegressor. This is a powerful model, capable of finding complex nonlinear relationships in the data</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="n">tree_reg</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>
<span class="n">tree_reg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DecisionTreeRegressor()
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Now that the model is trained, letâ€™s evaluate it on the training set:
</span><span class="n">housing_predictions</span> <span class="o">=</span> <span class="n">tree_reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">)</span>
<span class="n">tree_rmse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">housing_labels</span><span class="p">,</span> <span class="n">housing_predictions</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">tree_rmse</span>


</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.0
</code></pre></div></div>

<p>As we saw earlier, <code class="language-plaintext highlighter-rouge">we donâ€™t want to touch the test set until we are ready to launch a model</code> we are confident about, so we need to <code class="language-plaintext highlighter-rouge">use part of the training set for training and part of it for model validation</code>.</p>

<h1 id="better-evaluation-using-cross-validation">Better Evaluation Using Cross-Validation</h1>

<ul>
  <li>
    <p>One way to evaluate the Decision Tree model would be to use the <code class="language-plaintext highlighter-rouge">train_test_split()</code> function to split the training set into a smaller training set and a validation set, then train our models against the smaller training set and evaluate them against the validation set.</p>
  </li>
  <li>
    <p>A great alternative is to use <code class="language-plaintext highlighter-rouge">Scikit-Learnâ€™s K-fold cross-validation feature</code> : The following code <code class="language-plaintext highlighter-rouge">randomly splits the training set into 10 distinct subsets called folds</code>, then it <code class="language-plaintext highlighter-rouge">trains and evaluates the Decision Tree model 10 times</code>, <code class="language-plaintext highlighter-rouge">picking a different fold for evaluation every time</code> and <code class="language-plaintext highlighter-rouge">training on the other 9 folds</code>. 
The result is an array containing the 10 evaluation scores:</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># to get the 'scoring' options, use ssorted(sklearn.metrics.SCORERS.keys())
</span>
<span class="n">scores</span> <span class="o">=</span> <span class="o">-</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree_reg</span><span class="p">,</span> <span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_root_mean_squared_error'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">scores</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([71270.15951523, 68888.32011559, 64997.85188763, 69263.03318422,
       68197.14503697, 68963.98885461, 73536.17215975, 69183.4936482 ,
       66243.08004208, 71783.50940468])
</code></pre></div></div>

<ul>
  <li>to get the â€˜scoringâ€™ options, use ssorted(sklearn.metrics.SCORERS.keys())</li>
  <li>Scikit-Learnâ€™s cross-validation features <code class="language-plaintext highlighter-rouge">expect a utility function
(greater is better)</code> rather than a <code class="language-plaintext highlighter-rouge">cost function (lower is better)</code>, so <code class="language-plaintext highlighter-rouge">the scoring function is actually the opposite of the MSE (i.e., a negative value)</code></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># display the results 
</span><span class="k">def</span> <span class="nf">display_scores</span><span class="p">(</span><span class="n">scores</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Scores :'</span><span class="p">,</span><span class="n">scores</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Mean :'</span><span class="p">,</span><span class="n">scores</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Standard deviation :'</span><span class="p">,</span><span class="n">scores</span><span class="p">.</span><span class="n">std</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">display_scores</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Scores : [71270.15951523 68888.32011559 64997.85188763 69263.03318422
 68197.14503697 68963.98885461 73536.17215975 69183.4936482
 66243.08004208 71783.50940468]
Mean : 69232.67538489516
Standard deviation : 2394.0765898258674
</code></pre></div></div>

<ul>
  <li>Cross-validation allows you to get <code class="language-plaintext highlighter-rouge">not only an estimate of the performance of your model</code>, but also <code class="language-plaintext highlighter-rouge">a measure
of how precise this estimate is (i.e., its standard deviation)</code>. The Decision Tree has a
score of approximately 69,232, generally Â±2,394. We would not have this information if we just used one validation set.</li>
  <li>Letâ€™s compute the same scores for the Linear Regression model just to be sure:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lin_scores</span> <span class="o">=</span> <span class="o">-</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">lin_reg</span><span class="p">,</span><span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_root_mean_squared_error'</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">lin_scores</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([72229.03469752, 65318.2240289 , 67706.39604745, 69368.53738998,
       66767.61061621, 73003.75273869, 70522.24414582, 69440.77896541,
       66930.32945876, 70756.31946074])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">display_scores</span><span class="p">(</span><span class="n">lin_scores</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Scores : [72229.03469752 65318.2240289  67706.39604745 69368.53738998
 66767.61061621 73003.75273869 70522.24414582 69440.77896541
 66930.32945876 70756.31946074]
Mean : 69204.32275494766
Standard deviation : 2372.07079105592
</code></pre></div></div>

<p>The Decision Tree model is <code class="language-plaintext highlighter-rouge">overfitting so badly that it performs worse than the Linear Regression model</code>.</p>

<p>Letâ€™s try one last model now: the RandomForestRegressor : <code class="language-plaintext highlighter-rouge">Random Forests work by training many Decision Trees on random subsets of the features, then averaging out their predictions</code>. Building a model on top of many
other models is called <code class="language-plaintext highlighter-rouge">Ensemble Learning</code>, and it is often a great way to push ML algorithms
even further.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="n">forest_reg</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>
<span class="n">forest_reg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RandomForestRegressor()
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">forest_reg_scores</span> <span class="o">=</span> <span class="o">-</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">forest_reg</span><span class="p">,</span><span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_root_mean_squared_error'</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">forest_reg_scores</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([50311.08798022, 49043.69572163, 46081.95238283, 50467.56214907,
       47657.84153211, 49419.96274189, 51772.42197545, 49030.57976501,
       47498.17482111, 53167.33074077])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">display_scores</span><span class="p">(</span><span class="n">forest_reg_scores</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Scores : [50311.08798022 49043.69572163 46081.95238283 50467.56214907
 47657.84153211 49419.96274189 51772.42197545 49030.57976501
 47498.17482111 53167.33074077]
Mean : 49445.06098101039
Standard deviation : 1992.3842490271882
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">forest_predictions</span> <span class="o">=</span> <span class="n">forest_reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">)</span>
<span class="n">forst_rmse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">housing_labels</span><span class="p">,</span> <span class="n">forest_predictions</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">forst_rmse</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>18266.74368085342
</code></pre></div></div>

<p>Note that <code class="language-plaintext highlighter-rouge">the score on the training set</code>(18,266) is still <code class="language-plaintext highlighter-rouge">much lower</code> than on <code class="language-plaintext highlighter-rouge">the validation sets</code>(49,445 +/-1992.38), meaning that the model is <code class="language-plaintext highlighter-rouge">still overfitting the training set</code>.</p>

<ul>
  <li>
    <p>We should <code class="language-plaintext highlighter-rouge">save every model</code> we experiment with so that er can come back easily to any model you want. Make sure you <code class="language-plaintext highlighter-rouge">save both the hyperparameters and the trained parameters</code>, as well as <code class="language-plaintext highlighter-rouge">the cross-validation scores and perhaps the actual predictions as well</code>. This will allow you to easily compare scores across model types, and compare the types of errors they make.</p>
  </li>
  <li>
    <p>We can easily save Scikit-Learn models by using Pythonâ€™s pickle module or by using <code class="language-plaintext highlighter-rouge">the joblib library</code>, which is more efficient at serializing large NumPy arrays (you can install this library using pip):</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pip</span> <span class="n">install</span> <span class="n">joblib</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Requirement already satisfied: joblib in /Users/rmbp/opt/anaconda3/lib/python3.7/site-packages (1.1.0)
Note: you may need to restart the kernel to use updated packages.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">joblib</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># random forest :
</span>
<span class="n">joblib</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">forest_reg</span><span class="p">,</span><span class="s">'rmd_forest.pkl'</span><span class="p">)</span> <span class="c1"># saving the model as pkl file and named 'rmd_forest.pkl
</span><span class="n">model_reload</span> <span class="o">=</span> <span class="n">joblib</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'rmd_forest.pkl'</span><span class="p">)</span> <span class="c1"># loading the model
</span><span class="n">rmd_forest_prediction</span> <span class="o">=</span> <span class="n">model_reload</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">)</span> <span class="c1"># saving the predictions
</span><span class="n">rmd_forest_rmse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">rmd_forest_prediction</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">)</span> <span class="c1"># saving the rmse on the train test to check overfit
</span><span class="n">rmd_forest_cross_validation</span> <span class="o">=</span> <span class="o">-</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">model_reload</span><span class="p">,</span> <span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">,</span>
                             <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_root_mean_squared_error'</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># rmse on validation to check overfit
</span><span class="n">display_scores</span><span class="p">(</span><span class="n">rmd_forest_cross_validation</span><span class="p">)</span> <span class="c1"># cross validation score
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Scores : [50992.51555592 49288.84220573 46237.11091931 50248.85062075
 47806.3116179  49272.797347   51801.0468531  48800.83283468
 47540.31917616 53091.63650718]
Mean : 49508.0263637728
Standard deviation : 1972.8867918884973
</code></pre></div></div>

<h1 id="fine-tune-our-model">Fine-Tune Our Model</h1>

<h2 id="grid-search">Grid Search</h2>

<p>Using Scikit-Learnâ€™s GridSearchCV, All we need to do is <code class="language-plaintext highlighter-rouge">tell it which hyperparameters</code> we want it to experiment with and <code class="language-plaintext highlighter-rouge">what values</code>to try out, and it will use <code class="language-plaintext highlighter-rouge">cross-validation</code> to evaluate all the possible <code class="language-plaintext highlighter-rouge">combinations</code> of
hyperparameter values :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">[</span>
<span class="p">{</span><span class="s">'n_estimators'</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span> <span class="s">'max_features'</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]},</span>
<span class="p">{</span><span class="s">'bootstrap'</span><span class="p">:</span> <span class="p">[</span><span class="bp">False</span><span class="p">],</span> <span class="s">'n_estimators'</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="s">'max_features'</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]},</span>
<span class="p">]</span>

<span class="n">forest_reg</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">forest_reg</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                          <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_root_mean_squared_error'</span><span class="p">,</span>
                          <span class="n">return_train_score</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">grid_search</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>GridSearchCV(cv=5, estimator=RandomForestRegressor(),
             param_grid=[{'max_features': [2, 4, 6, 8],
                          'n_estimators': [3, 10, 30]},
                         {'bootstrap': [False], 'max_features': [2, 3, 4],
                          'n_estimators': [3, 10]}],
             return_train_score=True, scoring='neg_root_mean_squared_error')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">?</span><span class="n">GridSearchCV</span>
</code></pre></div></div>

<ul>
  <li>This <code class="language-plaintext highlighter-rouge">param_grid</code> tells Scikit-Learn to first evaluate all <code class="language-plaintext highlighter-rouge">3 Ã— 4 = 12 combinations</code> of <code class="language-plaintext highlighter-rouge">n_estimators</code> and <code class="language-plaintext highlighter-rouge">max_features</code> hyperparameter values specified in the first dict.
-Then try all <code class="language-plaintext highlighter-rouge">2 Ã— 3 = 6 combinations</code> of hyperparameter values in the second dict, but this time with <code class="language-plaintext highlighter-rouge">the bootstrap hyperparameter</code> set to False instead of True</li>
  <li>The grid search will explore <code class="language-plaintext highlighter-rouge">12 + 6 = 18</code> combinations of <code class="language-plaintext highlighter-rouge">RandomForestRegressor hyperparameter values</code>`</li>
  <li>And it will train each model 5 times (cv=5).In other words, all in all, there will be <code class="language-plaintext highlighter-rouge">18 Ã— 5 = 90</code> rounds of training.</li>
</ul>

<p>We can get the best combination of parameters like this :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grid_search</span><span class="p">.</span><span class="n">best_params_</span>

<span class="c1">#we should probably try searching again with higher values; the score may continue to improve.
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'max_features': 8, 'n_estimators': 30}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grid_search</span><span class="p">.</span><span class="n">best_estimator_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RandomForestRegressor(max_features=8, n_estimators=30)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cvres</span> <span class="o">=</span> <span class="n">grid_search</span><span class="p">.</span><span class="n">cv_results_</span>
<span class="k">for</span> <span class="n">mean_score</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">cvres</span><span class="p">[</span><span class="s">"mean_test_score"</span><span class="p">],</span> <span class="n">cvres</span><span class="p">[</span><span class="s">"params"</span><span class="p">]):</span>
        <span class="k">print</span><span class="p">(</span><span class="o">-</span><span class="n">mean_score</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>64530.85647414619 {'max_features': 2, 'n_estimators': 3}
55067.77832337284 {'max_features': 2, 'n_estimators': 10}
52781.7167175866 {'max_features': 2, 'n_estimators': 30}
60327.066875895776 {'max_features': 4, 'n_estimators': 3}
52586.95798629394 {'max_features': 4, 'n_estimators': 10}
50346.63948997191 {'max_features': 4, 'n_estimators': 30}
58398.87657548992 {'max_features': 6, 'n_estimators': 3}
52075.368300249116 {'max_features': 6, 'n_estimators': 10}
50093.621910952315 {'max_features': 6, 'n_estimators': 30}
58628.430409285626 {'max_features': 8, 'n_estimators': 3}
51936.797178963665 {'max_features': 8, 'n_estimators': 10}
50089.501357132904 {'max_features': 8, 'n_estimators': 30}
62303.627420601595 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}
54183.89357722118 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}
60004.47703668058 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}
52603.81684475204 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}
58002.985249363366 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}
52121.979634950054 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}
</code></pre></div></div>

<p>Rq: Donâ€™t forget that we can treat some of the data preparation steps as hyperparameters. The grid search will automatically find out whether or not to add a feature you were not sure about. Ex : using the add_bedrooms_per_room hyperparameter of your CombinedAttributesAdder transformer).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
