{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad33d434",
   "metadata": {},
   "source": [
    "# US cencus income : Ensembles, Bagging and Shap Values\n",
    "\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [fastpages, jupyter]\n",
    "- image: images/shap_values.png\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de85c1",
   "metadata": {},
   "source": [
    "# Problem Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a8be9",
   "metadata": {},
   "source": [
    "Our task is to determine the income level for the person represented by the record. Incomes have been binned at the $50K level to present a **binary classification problem**.\n",
    "\n",
    "The dataset used in this analysis was extracted from the census bureau database found at. The data was split into train/test in approximately 2/3, 1/3 proportions.\n",
    "\n",
    "The following mappings of the data is as follow :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eaaaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(f'{PATH}/census_income_metadata_column.csv', sep=';')\n",
    "df_labels.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ee235",
   "metadata": {},
   "source": [
    "In any sort of data science work, it's important to look at our data directly to make sure we understand the format, how it's stored, what types of values it holds, etc. Even if we've read a description of the data, the actual data may not be what we expect. We'll start by reading the training set into a Pandas DataFrame :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26aaed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train data \n",
    "df = pd.read_csv(f'{PATH}/census_income_learn.csv', names = df_labels['column_name'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62edd5",
   "metadata": {},
   "source": [
    "Let's have a look at the columns, their types defined by Pandas and compared it to their actual mapping types :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08687e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chekcing the mapping of the data \n",
    "d1 = df.dtypes.apply(lambda x: x.name).to_dict()\n",
    "d2 = {c: d for c,d in zip(df_labels['column_name'],df_labels['dtype'])}\n",
    "mapping = [d1, d2]\n",
    "d = {}\n",
    "for k in d1.keys():\n",
    "    d[k] = tuple(d[k] for d in mapping)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5264a2b",
   "metadata": {},
   "source": [
    "We can see that **detailed_industry_recode**, **detailed_occupation_recode**, **own_business_or_self_employed**,\n",
    "**veterans_benefits** and **year** is set by default as a continuos category. \n",
    "\n",
    "Let's redifined their types :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting data types\n",
    "d1['detailed_industry_recode']='object'\n",
    "d1['detailed_occupation_recode']='object'\n",
    "d1['own_business_or_self_employed']='object'\n",
    "d1['veterans_benefits']='object'\n",
    "d1['year']='object'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e2a8f",
   "metadata": {},
   "source": [
    "Let's reload the data with its correspind feature's mapping :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b961f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload data with coorexted types\n",
    "df = pd.read_csv(f'{PATH}/census_income_learn.csv', names =df_labels['column_name'],\n",
    "                 dtype= d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34720e3b",
   "metadata": {},
   "source": [
    "The **info()** method is useful to get a quick description of the data, in particular the\n",
    "total number of rows, each attribute’s type, and the number of nonnull values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a86f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispplay first rows \n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  \n",
    "        display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da39d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'ignore' column\n",
    "df.drop('ignore', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b3321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9389976f",
   "metadata": {},
   "source": [
    "We load the test set with the same training data types :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed72f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the test set \n",
    "test = pd.read_csv(f'{PATH}/census_income_test.csv', names =df_labels['column_name'], dtype= d1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a71e84",
   "metadata": {},
   "source": [
    "We verify if we got the same columns both on the train and the test set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2dcef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking columns on test set which not in train\n",
    "set(test.columns).difference(set(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c5f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping 'ignore' columns\n",
    "test.drop('ignore', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62418d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe741c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display first rows of the test set\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        display(test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b711d",
   "metadata": {},
   "source": [
    "# Looking at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a043dacb",
   "metadata": {},
   "source": [
    "The most important data column is the **dependent variable**—that is, the one we want to predict which is **income_level** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ecb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'income_level'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7587814",
   "metadata": {},
   "source": [
    "Let's see its distribution :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad282948",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[dep_var].value_counts(normalize = True))\n",
    "df[dep_var].value_counts(normalize = True).plot(kind='bar',\n",
    "                                 edgecolor='black',\n",
    "                                 color='blue',\n",
    "                                 title='income_level')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4820092",
   "metadata": {},
   "source": [
    "We have an **imbalanced dataset** where the income level of -50k is representing more than 93% of the total records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80053f",
   "metadata": {},
   "source": [
    "Next, we automatically handle which columns are **continuous** and which are **categorical** :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88665c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get categorical and numerical variables\n",
    "def cont_cat_split(df, dep_var=None):\n",
    "    \"Helper function that returns column names of cont and cat variables from given `df`.\"\n",
    "    cont_names, cat_names = [], []\n",
    "    for label in df:\n",
    "        if label in [dep_var]: continue\n",
    "        if (pd.api.types.is_integer_dtype(df[label].dtype) or\n",
    "            pd.api.types.is_float_dtype(df[label].dtype)):\n",
    "            cont_names.append(label)\n",
    "        else: cat_names.append(label)\n",
    "    return cont_names, cat_names\n",
    "\n",
    "cont, cat = cont_cat_split(df, dep_var= dep_var)\n",
    "cont , cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca058693",
   "metadata": {},
   "source": [
    "Let's start by checking the modalties of our categorical variables :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8af32f",
   "metadata": {},
   "source": [
    "Some categorical features are **purely nominal**-having multiple modalities (with modality **?** for nan values) and \n",
    "others are **ordinal columns** like **education** and **year**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ediucation modalities\n",
    "df['education'].unique(), df['education'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f69489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year modalities\n",
    "df['year'].unique(), df['year'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4284df",
   "metadata": {},
   "source": [
    "We can tell Pandas about a suitable ordering of these levels like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f81153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the order of education variable\n",
    "education = ' Children',' Less than 1st grade',' 1st 2nd 3rd or 4th grade',' 5th or 6th grade',\\\n",
    "' 7th and 8th grade',' 9th grade',' 10th grade',' 11th grade', ' 12th grade no diploma',\\\n",
    "' High school graduate', ' Associates degree-academic program',' Associates degree-occup /vocational',\\\n",
    "' Prof school degree (MD DDS DVM LLB JD)',' Some college but no degree',' Bachelors degree(BA AB BS)',\\\n",
    "' Masters degree(MA MS MEng MEd MSW MBA)',' Doctorate degree(PhD EdD)'\n",
    "len(education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the order of year variaable\n",
    "year = '94', '95'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the defined ordering fot our data :\n",
    "df['education'] = df['education'].astype('category')\n",
    "df['education'].cat.set_categories(education, ordered=True, inplace=True)\n",
    "\n",
    "df['year'] = df['year'].astype('category')\n",
    "df['year'].cat.set_categories(year, ordered=True, inplace=True)\n",
    "\n",
    "#Same for test set :\n",
    "test['education'] = test['education'].astype('category')\n",
    "test['education'].cat.set_categories(education, ordered=True, inplace=True)\n",
    "\n",
    "test['year'] = test['year'].astype('category')\n",
    "test['year'].cat.set_categories(year, ordered=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0665fa72",
   "metadata": {},
   "source": [
    "Lets check our continous features: \n",
    "The **describe()** method shows a summary of the numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed133bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cont].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaef32c",
   "metadata": {},
   "source": [
    "The **count**, **mean**, **min**, and **max** rows are self-explanatory.The **std** row shows the standard deviation, which measures how dispersed the values are. The 25%, 50%, and 75% rows show the corresponding percentiles.\n",
    "\n",
    "We plot a histogram for each numerical attribute :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e64c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "df[cont].hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87670eb2",
   "metadata": {},
   "source": [
    "- We can see that these attributes have very **different scales**.\n",
    "\n",
    "- Some numerical varaibles are countinous like **age** and others are discrete and finite like **weeks_worked_in_year** or infinete **num_persons_worked_for_employer**.\n",
    "\n",
    "- Some features as **wage_per_hour**,**capital_gains**,**capital_losses**,**dividends_from_stocks** are tail-heavy: they extend much farther to the median right with high coefficient of variation :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cont].boxplot(column=['wage_per_hour','capital_gains','capital_losses','dividends_from_stocks'],\n",
    "                 figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d92c04",
   "metadata": {},
   "source": [
    "We can see the presence of **extreme values** for those features.\n",
    "\n",
    "Using the **skewness value**, which explains the extent to which the data is normally distributed, in order to confirm that. \n",
    "Ideally, the skewness value should be between -1 and +1, and any major deviation from this range indicates the presence of extreme values.\n",
    "\n",
    "We can calculate the skwenss value :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38b02e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewness value\n",
    "df[['wage_per_hour','capital_gains','capital_losses','dividends_from_stocks']].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea8eca4",
   "metadata": {},
   "source": [
    "Using the **IQR score**, let's see the number of obseravtions that are not in the `(Q1 - 1.5 IQR) and (Q3 + 1.5 IQR)` range :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee28508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR score\n",
    "Q1 = df[['wage_per_hour','capital_gains','capital_losses','dividends_from_stocks']].quantile(0.25)\n",
    "Q3 = df[['wage_per_hour','capital_gains','capital_losses','dividends_from_stocks']].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of observation out of the definied range\n",
    "out = df[['wage_per_hour','capital_gains','capital_losses','dividends_from_stocks']]\n",
    "df_out = out[((out < (Q1 - 1.5 * IQR)) |(out > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "out.shape, df_out.shape, df_out.shape[0]/out.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d52ac",
   "metadata": {},
   "source": [
    "From 199.523 observation of the selcted features, 38.859 records (19%) represent extrem values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b8bcb",
   "metadata": {},
   "source": [
    "For **weeks_worked_in_year** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weeks_worked_in_year'].plot( kind='hist',\n",
    "                                 bins=53,\n",
    "                                 edgecolor='black',\n",
    "                                 color='blue',\n",
    "                                 title='weeks worked in a year',\n",
    "                                 figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c1c1b",
   "metadata": {},
   "source": [
    "For **num_persons_worked_for_employer** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a727d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_persons_worked_for_employer'].plot( kind='hist',\n",
    "                                 \n",
    "                                 edgecolor='black',\n",
    "                                 color='blue',\n",
    "                                 title='num_persons_worked_for_employer',\n",
    "                                 figsize=(7,5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ccf2a1",
   "metadata": {},
   "source": [
    "We notice an increase in the 7th bins **num_persons_worked_for_employer=6**. Check if this variable is capped ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204a951",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05884b2b",
   "metadata": {},
   "source": [
    "- Starting with **numerical variables** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19120b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dia = df[dep_var]\n",
    "data = df[['age']]\n",
    "data = pd.concat([data_dia,data],axis=1)\n",
    "data = pd.melt(data,id_vars=\"income_level\",\n",
    "                    var_name=\"features\",\n",
    "                    value_name='value')\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.violinplot(x=\"features\", y=\"value\", hue=\"income_level\", data=data,split=True, inner=\"quartile\")\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccb10ab",
   "metadata": {},
   "source": [
    "For the **age** feature, we can see that the medians of the income levels +/- 50k look separated. \n",
    "The income level of +50k with a median of 50 years old has a lower interquntile range (IQR) with value spread of 10 years. Whereas The income level of -50k has a median of 30 years old has and interquantile range (IQR) of 40 years.\n",
    "So, **age** can be good for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bdcdad",
   "metadata": {},
   "source": [
    "Let's look at the **weeks_worked_in_year** feature :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20805d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of income class in each week\n",
    "weeks_worked_in_year = df.groupby([\"weeks_worked_in_year\", \"income_level\"])\\\n",
    "                        .size()\\\n",
    "                        .groupby(level=0).apply(lambda x: 100*x/x.sum()).unstack()\n",
    "\n",
    "# print the percentage class for the first and last weeks \n",
    "weeks_worked_in_year.iloc[[0,1,2, -3,-2,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks_worked_in_year.plot(kind='bar', \n",
    "                          stacked=True,\n",
    "                          edgecolor='black', \n",
    "                          figsize=(12,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d1f38",
   "metadata": {},
   "source": [
    "We can see that the propotion of people making more than 50k a year is increasing with the number of working weeks in a given year where it can reach more than 14% for those working 52 weeks . \n",
    "However, the -50k level of income is representing the higher propotion regardless of the number of working weeks.\n",
    "We notice that among those how don't work at all, 0.6% still make more than 50k a year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634da7c4",
   "metadata": {},
   "source": [
    "Let's look at **num_persons_worked_for_employer** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ef8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_persons_worked_for_employer = df.groupby([\"num_persons_worked_for_employer\", \"income_level\"])\\\n",
    "                        .size()\\\n",
    "                        .groupby(level=0).apply(lambda x: 100*x/x.sum()).unstack()\n",
    "\n",
    "num_persons_worked_for_employer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4578dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_persons_worked_for_employer.plot(kind='bar', \n",
    "                          stacked=True,\n",
    "                          edgecolor='black', \n",
    "                          figsize=(12,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b636f",
   "metadata": {},
   "source": [
    "The proportion of +50k income level increases with the number of the num_preson_worked_for_employer where it reaches **16% for num_preson_worked_for_employer= 6**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9a7e78",
   "metadata": {},
   "source": [
    "Let's see the average of **wage_per_hour**,**capital_gains**,**capital_losses**,**dividends_from_stocks** across the income levels :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ffb2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = df[['wage_per_hour','capital_gains','capital_losses','dividends_from_stocks','income_level']]\\\n",
    ".groupby('income_level')\\\n",
    ".mean()\n",
    "\n",
    "avg.plot(kind='bar', title = 'average across income levels', figsize=(10,5))\n",
    "\n",
    "avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a0124d",
   "metadata": {},
   "source": [
    "We can see that people making more than 50k a year, have on average, **higher wage per hour**,**higher return on capital asset** and **dividends from stock options**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2934140",
   "metadata": {},
   "source": [
    "- Next, let's analyse some **categorical variables** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e36a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education variable\n",
    "pd.crosstab(df['income_level'], \n",
    "            df['education'],\n",
    "            margins = True,\n",
    "           normalize = 'columns').style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71b7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['income_level'], \n",
    "            df['education'],\n",
    "            margins = True,\n",
    "           normalize = 'columns').plot(kind='bar',stacked=True, edgecolor='black', \n",
    "                          figsize=(12,10))\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.5, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd99901",
   "metadata": {},
   "source": [
    "We can see the effect of education on income level where more than 50% of **Prof school degree** and **Doctorate degree** earn more than 50k a year. On the other hand, the majority of people (more than 90%) with **no degree** earn less than 50k a year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee3956",
   "metadata": {},
   "source": [
    "Let's further this analysis and see the effect of **education** and **the number of working weeks** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f6eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['income_level'], \n",
    "            df['education'],\n",
    "            values = df['weeks_worked_in_year'],\n",
    "            aggfunc = 'mean').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eabe5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(20, 4))\n",
    "sns.heatmap(\n",
    "    pd.crosstab(df['income_level'], \n",
    "            df['education'],\n",
    "            values = df['weeks_worked_in_year'],\n",
    "            aggfunc = 'mean').round(1) \n",
    "    ,annot = True\n",
    "    ,linewidths=.5\n",
    "    ,cmap=\"YlGnBu\"\n",
    "    \n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff0d99c",
   "metadata": {},
   "source": [
    "We can see that earning more than 50k a year demands high level of education but also lot of hard work !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5cb52",
   "metadata": {},
   "source": [
    "Let's analyse the effect of **sex** and **marital_stat** on income level : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3615ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['income_level'], \n",
    "            [df['sex'],df['marital_stat']],\n",
    "           margins = True,\n",
    "           normalize = 'columns').style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['income_level'], \n",
    "            [df['sex'],df['marital_stat']]).plot(kind='bar',stacked=True, edgecolor='black',\n",
    "                                                 \n",
    "                          figsize=(12,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72150a58",
   "metadata": {},
   "source": [
    "We can see that the highest proportion of people earning less than 50k a year are mostly **female Married-A F spouse present** or **never married** and **seperated male**. On the other hand, **male Married-civilian spouse present** represent the highest propotion on the +50k income level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf97bd",
   "metadata": {},
   "source": [
    "We can further the analysis more as we have got many interesting features with several modalities but for now let's see how machine learning models can help us understanding more our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe138ad",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf527c",
   "metadata": {},
   "source": [
    "We set **the feature vector** and **the target variable** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d5ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting feature vector and target variable for the train set\n",
    "\n",
    "X = df.drop(['income_level'], axis = 1)\n",
    "y = df['income_level']\n",
    "\n",
    "# setting feature vector and target variable for the test set\n",
    "test_x = test.drop(['income_level'], axis = 1)\n",
    "test_y = test['income_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd73371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheching the result\n",
    "df.shape, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e7dba",
   "metadata": {},
   "source": [
    "We will keep the provided **test set** hidden and will use it as a realtime dataset when we make our model on production in order to avoid the risk of **data snooping**. \n",
    "\n",
    "For that, we will be using a validation set derived from our training set (30%). Scikit-Learn provides a few functions to split datasets into multiple subsets in various ways. The simplest function is **train_test_split()**.\n",
    "\n",
    "Since we have an imbalanced dataset, we can't considered purely random sampling methods. For that, we do stratified sampling based on the **income level**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29903b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  y, \n",
    "                                                  test_size=0.3, \n",
    "                                                  random_state=12,\n",
    "                                                  stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the train and validation set\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a954400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the income level proportion\n",
    "y_train.value_counts(normalize = True), y_val.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8072e",
   "metadata": {},
   "source": [
    "What if we didn't stratify with respect to income level ?\n",
    "\n",
    "We can compare the income level  proportions in the **overall dataset**, in\n",
    "the **test set** generated with `stratified sampling`, and in **a test set** generated using `purely random sampling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def income_cat_proportions(data):\n",
    "    return data[\"income_level\"].value_counts() / len(data)\n",
    "\n",
    "train_set, test_set = train_test_split(df, test_size=0.3, random_state=12)\n",
    "\n",
    "train_set, test_set_strat = train_test_split(df, test_size=0.3, random_state=12,stratify=df['income_level'])\n",
    "\n",
    "compare_props = pd.DataFrame({\n",
    "    \"Overall\": income_cat_proportions(df),\n",
    "    \"Stratified\": income_cat_proportions(test_set_strat),\n",
    "    \"Random\": income_cat_proportions(test_set),\n",
    "}).sort_index()\n",
    "compare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\n",
    "compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2c77e",
   "metadata": {},
   "source": [
    "As we can see, the test set generated using stratified sampling has\n",
    "income level proportions almost identical to those in the full dataset, whereas the\n",
    "test set generated using purely random sampling is skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11277fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_props"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08574d7b",
   "metadata": {},
   "source": [
    "Now that we defined our training set, It’s time to prepare the data for our machine Learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49922a70",
   "metadata": {},
   "source": [
    "- Data cleaning :\n",
    "\n",
    "We have seen previously that we don't have any **missing values**. For some cataegorical features, we assumed that the **?** modality is encoded for NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f164240f",
   "metadata": {},
   "source": [
    "- Handling Text and Categorical Attributes :\n",
    "\n",
    "Strating with the target variable **income_level**, we use **LabelEncoder()** to encode target labels with value between 0 and `n_classes-1 = 1`.\n",
    "\n",
    "We have seen also that we have some ordinal variable as **education** and **year**, so we use **OrdinalEncoder** to encode the categorical features as an integer array. The results in a single column of integers (0 to n_categories - 1) per feature.\n",
    "\n",
    "Since the remaining categorical features have several modalities per feature, we use also **OrdinalEncoder** instead of **OneHotEncoder**.\n",
    "> Working with **OneHotEncoder** leads, in our case, to high memory consumption. We can combine **OneHotEncoder** and **PCA** : The benefit in PCA is that combination of N attributes is better than any individual attribute. And the disadvantage is in harder explanation what exactly that PCA component means. \n",
    "Therefore, for this work, we will sacrifice a bit of predictive power to get more understandable model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eae9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical variables encoding\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "\n",
    "# For the traget varaible\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)  #fit on training set\n",
    "y_val = le.transform(y_val)    \n",
    "test_y = le.transform(test_y) \n",
    "\n",
    "\n",
    "# For categorical features :\n",
    "Or = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value = -1)\n",
    "for c in cat : \n",
    "        X_train[c] = Or.fit_transform(np.array(X_train[c]).reshape(-1,1).astype(str))  #fit on training set\n",
    "        X_val[c] = Or.transform(np.array(X_val[c]).reshape(-1,1).astype(str))\n",
    "        test_x[c] = Or.transform(np.array(test_x[c]).reshape(-1,1).astype(str))\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907dc8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheking categorical features encoding\n",
    "X_train[cat].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5cca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheking target feature encoding\n",
    "set(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145257a",
   "metadata": {},
   "source": [
    "- Feature Scaling :\n",
    "\n",
    "We saw previously that out numerical inputs have different scales like the **weeks_worked_in_year** and **capital_gains**. We will be using **StandardScaler** since standardization is much less affected by outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388148f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for c in cont:\n",
    "    X_train[c] = scaler.fit_transform(np.array(X_train[c]).reshape(-1,1)) # fir on the train set\n",
    "    X_val[c] = scaler.transform(np.array(X_val[c]).reshape(-1,1))\n",
    "    test_x[c] = scaler.transform(np.array(test_x[c]).reshape(-1,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e669a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the standardization\n",
    "X_train[cont].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601e53c4",
   "metadata": {},
   "source": [
    "So far, we have handled the **categorical columns** and the **numerical columns** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f53489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the training set\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  \n",
    "        display(X_train.head(3))\n",
    "\n",
    "X_train.shape, X_val.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04466c8c",
   "metadata": {},
   "source": [
    "# Data modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ffaaa2",
   "metadata": {},
   "source": [
    "- Selecting a Performance Measure :\n",
    "\n",
    "**Accuracy** is the simplest way to measure the effectiveness of a\n",
    "classification task, and it's the percentage of correct predictions over all predictions.\n",
    "In other words, in a binary classification task, you can calculate this by adding the\n",
    "number of True Positives (TPs) and True Negatives (TNs) and dividing them by a\n",
    "tally of all predictions made. As with regression metrics, you can measure accuracy\n",
    "for both train and test to gauge **overfitting**.\n",
    "\n",
    "But, we can get an accuracy of 94%, which sounds pretty\n",
    "good, but it turns out we are always predicting **-50k**! In other words, even if\n",
    "we get high accuracy, it is meaningless unless we are predicting accurately for the\n",
    "least represented class, **+50k**.\n",
    "\n",
    "For this reasing, we will be using **F1-score**.\n",
    "The **F1-score** is also called the harmonic average of precision and recall because\n",
    "it's calculated like this: 2TP / 2TP + FP + FN. Since it includes both precision and\n",
    "recall metrics, which pertain to the proportion of true positives, it's a good metric\n",
    "choice to use when the dataset is **imbalanced**, and we don't prefer either precision\n",
    "or recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e73bce9",
   "metadata": {},
   "source": [
    "- Base model :\n",
    "\n",
    "Let's start with **Decision tree ensembles**.\n",
    "\n",
    "A decision tree asks a series of binary (that is, yes or no) questions about the data. After each question the data at that part of the tree is split between a \"yes\" and a \"no\" branch. After one or more questions, either a prediction can be made on the basis of all previous answers or another question is required.\n",
    "\n",
    "We illustarte a tree classification using **4 leaf nodes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d33366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "m = DecisionTreeClassifier(max_leaf_nodes=4, random_state=14) # to plot the tree classification\n",
    "m.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a101410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the class output\n",
    "m.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f46956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e4dba5",
   "metadata": {},
   "source": [
    "The top node represents the **initial model** before any splits have been done, when all the data is in the initial income levels. This is the simplest possible model. It is the result of asking zero questions and will always predict the more represented class which is -50k. We use the **Gini method** to create split points. The strategy  is to select each pair of adjacent values as a possible split-point and the point with smaller gini index chosen as the splitting point. In our case, the **capital gains** at 1.47 was choosen first.\n",
    "\n",
    "Moving down and to the left, this node shows us that there were 130,999 records for income level of -50k where **capital gains** was less than 1.47. The class predicted is -50k in this case. Moving down and to the right from the initial model takes us to the records where **capital gains** was greater than 1.47. The class predicted is +50k in this case where 1370 records have an income of +50k and **capital gains** >0.4\n",
    "\n",
    "The bottom row contains our leaf nodes: the nodes with no answers coming out of them, because there are no more questions to be answered.\n",
    "\n",
    "Returning back to the top node after the first decision point, we can see that a second binary decision split has been made, based on asking whether **weeks_worked_per_year** is less than or equal to 0.9. For the group where this is true, the class predicted is -50k with a gini of 0.019 and there are 85,411 records. For the records where this decision is false,  the class predicted is -50k with a gini of 0.019, and there are 52,361 records. So again, we can see that the decision tree algorithm has successfully split out more  records into two more groups which differ in gini value significantly.\n",
    "\n",
    "Now, let's run our base model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c878f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = DecisionTreeClassifier(random_state=14)\n",
    "m.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1feeaf",
   "metadata": {},
   "source": [
    "We evaluate the model on our validation set using **accuracy**, **recall** and **f1 score** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a9043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "\n",
    "# on the train set \n",
    "accuracy_score(y_train,m.predict(X_train)) , \\\n",
    "recall_score(y_train,m.predict(X_train)), \\\n",
    "f1_score(y_train,m.predict(X_train), average='binary', pos_label=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7875c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the valid set \n",
    "accuracy_score(y_val,m.predict(X_val)) , \\\n",
    "recall_score(y_val,m.predict(X_val)), \\\n",
    "f1_score(y_val,m.predict(X_val), average='binary', pos_label=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c753be9",
   "metadata": {},
   "source": [
    "It's seems that we are doing badly on the validation set. Let's see houw many leaf nodes we got :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5323ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_n_leaves(), len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b45bc2",
   "metadata": {},
   "source": [
    "Sklearn's default settings allow it to continue splitting nodes until there is only one item in each leaf node. Let's change the stopping rule to tell sklearn to ensure every leaf node contains at least 25 records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ac805",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = DecisionTreeClassifier(min_samples_leaf=25,random_state=14)\n",
    "m.fit(X_train, y_train)\n",
    "\n",
    "# on the train set \n",
    "accuracy_score(y_train,m.predict(X_train)) , \\\n",
    "recall_score(y_train,m.predict(X_train)), \\\n",
    "f1_score(y_train,m.predict(X_train), average='binary', pos_label=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7bccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the valid set \n",
    "accuracy_score(y_val,m.predict(X_val)) , \\\n",
    "recall_score(y_val,m.predict(X_val)), \\\n",
    "f1_score(y_val,m.predict(X_val), average='binary', pos_label=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aef02a",
   "metadata": {},
   "source": [
    "That looks much better. Let's check the number of leaves again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5183966",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_n_leaves(), len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64601887",
   "metadata": {},
   "source": [
    "We got less leaf nodes than before. So, the more we increase the number of leaf nodes, the more is the possibility of **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2760d9",
   "metadata": {},
   "source": [
    "Building a **decision tree** is a good way to create a model of our data. It is very flexible, since it can clearly handle nonlinear relationships and interactions between variables. But we can see there is a fundamental compromise between how well it generalizes (which we can achieve by creating small trees) and how accurate it is on the training set (which we can achieve by using large trees).\n",
    "\n",
    "So how do we get the best of both worlds?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ed7120",
   "metadata": {},
   "source": [
    "- Ensembling :\n",
    "\n",
    "An an example of an Ensemble method is **Random Forest** : we can train a group of Decision Tree classifiers,\n",
    "each on a different random subset of the training set. The process of subseting the data is called **bagging** done with **max_samples** hyperparameter ( we set it at 100.00 samples) and the ramdom selection process this called **bootsraping** done by setting **bootstrap = True**.\n",
    "\n",
    "With bagging, some instances may be sampled several times for any given predictor, while others may not be sampled at all. The remaining  sampled are called **out-of-bag (oob) instances** used as **validation set** in the training process and done by setting **oob_score=True**.\n",
    "\n",
    "We train a Random Forest classifier **with 50 trees** (each limited to **minimum 5 samples per leaf**).\n",
    "and instead of searching for the very best feature when splitting a node, we\n",
    "searches for the best feature among a random subset of 50% of our initial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d084a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 50, max_samples=100_000, max_features=0.5, min_samples_leaf= 5, \n",
    "                            bootstrap= True,oob_score = True,random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the train set \n",
    "accuracy_score(y_train,rf.predict(X_train)) , \\\n",
    "recall_score(y_train,rf.predict(X_train)), \\\n",
    "f1_score(y_train,rf.predict(X_train), average='binary', pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91827f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the valid set \n",
    "accuracy_score(y_val,rf.predict(X_val)) , \\\n",
    "recall_score(y_val,rf.predict(X_val)), \\\n",
    "f1_score(y_val,rf.predict(X_val), average='binary', pos_label=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82f54cc",
   "metadata": {},
   "source": [
    "Looking at what happens to the **oob error rate** as we add more and more trees, we you can see that the improvement levels off quite a bit after around 40 trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ea983",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores =[]\n",
    "for k in range(1, 50):\n",
    "    rfc = RandomForestClassifier(n_estimators = k, max_samples=100_000, max_features=0.5, min_samples_leaf= 5, \n",
    "                            bootstrap= True,oob_score = True,random_state=14)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    #y_pred = rfc.predict(X_val)\n",
    "    #scores.append(accuracy_score(y_test, y_pred)) oob_score_\n",
    "    oob_error = 1 - rfc.oob_score_\n",
    "    scores.append(oob_error)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the relationship between K and testing accuracy\n",
    "# plt.plot(x_axis, y_axis)\n",
    "plt.plot(range(1, 50), scores)\n",
    "plt.xlabel('Value of n_estimators for Random Forest Classifier')\n",
    "#plt.ylabel('Testing Accuracy')\n",
    "plt.ylabel('OOB error rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1643b017",
   "metadata": {},
   "source": [
    "Let's try to improve our model : \n",
    "\n",
    "We may ask **which columns are the strongest predictors, which can we ignore?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc364b8",
   "metadata": {},
   "source": [
    "It's not normally enough just to know that a model can make accurate predictions—we also want to know how it's making predictions. Feature importance gives us insight into this. We can get these directly from sklearn's random forest by looking in the feature_importances_ attribute. Here's a simple function we can use to pop them into a DataFrame and sort them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_feat_importance(rf, X_train)\n",
    "fi[:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa5308",
   "metadata": {},
   "source": [
    "The feature importances for our model show that the first few most important columns have much higher importance scores than the rest, with (not surprisingly) **capital_gains** and **dividends_from_stocks** being at the top of the list.\n",
    "\n",
    "A plot of the feature importances shows the relative importances more clearly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fc43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fi(fi):\n",
    "    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n",
    "\n",
    "plot_fi(fi[:30]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aae4a9",
   "metadata": {},
   "source": [
    "The way these importances are calculated is quite simple yet elegant. The feature importance algorithm loops through each tree, and then recursively explores each branch. At each branch, it looks to see what feature was used for that split, and how much the model improves as a result of that split. The improvement (weighted by the number of rows in that group) is added to the importance score for that feature. This is summed across all branches of all trees, and finally the scores are normalized such that they add to 1.\n",
    "\n",
    "It seems likely that we could use just a subset of the columns by removing the variables of low importance and still get good results. Let's try just keeping those with a feature importance greater than **0.005**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = fi[fi.imp>0.005].cols\n",
    "len(to_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55a3bb4",
   "metadata": {},
   "source": [
    "We can retrain our model using just this subset of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aabeeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imp = X_train[to_keep]\n",
    "X_val_imp = X_val[to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d1a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestClassifier(n_estimators = 50, max_samples=100_000, max_features=0.5, min_samples_leaf= 5, \n",
    "                            bootstrap= True,oob_score = True,random_state=14)\n",
    "\n",
    "m.fit(X_train_imp,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f665f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the train set \n",
    "accuracy_score(y_train,m.predict(X_train_imp)) , \\\n",
    "recall_score(y_train,m.predict(X_train_imp)), \\\n",
    "f1_score(y_train,m.predict(X_train_imp), average='binary', pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ace7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the valid set \n",
    "accuracy_score(y_val,m.predict(X_val_imp)) , \\\n",
    "recall_score(y_val,m.predict(X_val_imp)), \\\n",
    "f1_score(y_val,m.predict(X_val_imp), average='binary', pos_label=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c0ff3",
   "metadata": {},
   "source": [
    "Our **accuracy is about the same**, but we have **far fewer columns** to study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4384f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train.columns), len(X_train_imp.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e90f279",
   "metadata": {},
   "source": [
    "We've found that generally the first step to improving a model is **simplifying it**—48 columns was too many for us to study them all in depth! Furthermore, in practice often a simpler, more interpretable model is easier to roll out and maintain.\n",
    "\n",
    "This also makes our feature importance plot easier to interpret. Let's look at it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fi(rf_feat_importance(m, X_train_imp));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fcb198",
   "metadata": {},
   "source": [
    "Let's see if we have redundent feature in our model by determining their similarities :\n",
    "\n",
    "> Determining Similarity: The most similar pairs are found by calculating the rank correlation, which means that all the values are replaced with their rank (i.e., first, second, third, etc. within the column), and then the correlation is calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3638a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.cluster import hierarchy as hc\n",
    "\n",
    "def cluster_columns(df, figsize=(10,6), font_size=12):\n",
    "    corr = np.round(scipy.stats.spearmanr(df).correlation, 4)\n",
    "    corr_condensed = hc.distance.squareform(1-corr)\n",
    "    z = hc.linkage(corr_condensed, method='average')\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    hc.dendrogram(z, labels=df.columns, orientation='left', leaf_font_size=font_size)\n",
    "    plt.show()\n",
    "\n",
    "cluster_columns(X_train_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d003779",
   "metadata": {},
   "source": [
    "Looking good! This is really not much worse than the model with all the fields. Let's create DataFrames without these columns, and save them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790719da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train_imp # train\n",
    "X_val_final = X_val_imp # valid \n",
    "\n",
    "test_x_final = test_x[to_keep] # test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea5af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final.shape , X_val_final.shape, test_x_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634ec23d",
   "metadata": {},
   "source": [
    "# Model Assesment :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1094dc41",
   "metadata": {},
   "source": [
    "We have seen the **DecisionTreeClassifier** as our basemodel, then we tried **RandomForestClassifier** and finaly we tried to optimize so we can have less features for better interpretation. \n",
    "\n",
    "Here is the model metrics on our **validation set** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4abf0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_metrics = {'DTC': [0.95, 0.42, 0.51], \n",
    "                 'RF': [0.96, 0.42, 0.53],\n",
    "                 'RF_less_feat': [0.95, 0.41, 0.53]\n",
    "                 \n",
    "                }\n",
    "df = pd.DataFrame(data = models_metrics)\n",
    "df.rename(index={0:'Accuracy',1:'Recall', 2: 'F1 score'}, \n",
    "                 inplace=True)\n",
    "ax = df.plot(kind='bar', figsize = (10,5), \n",
    "        color = ['gold', 'lightgreen','lightcoral'],\n",
    "        rot = 0, title ='Models performance',\n",
    "        edgecolor = 'grey', alpha = 0.5)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.01, p.get_height() * 1.0005))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1c1dbf",
   "metadata": {},
   "source": [
    "Based on **F1 score**, we select the **RandomForestClassifier** with 25 features as our best model.\n",
    "\n",
    "\n",
    "Let's see the **experiment results*** of this model :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad62806b",
   "metadata": {},
   "source": [
    "The **precision_recall_curve** and **roc_curve** are useful tools to visualize the **sensitivity-specificty** tradeoff in the classifier. They help inform a data scientist where to set the decision threshold of the model to maximize either sensitivity or specificity. This is called the **operating point** of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve, \\\n",
    "auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaab749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an array of the class probabilites called y_scores\n",
    "y_scores = m.predict_proba(X_val_imp)[:, 1]\n",
    "\n",
    "# we enerate the precision-recall curve for the classifier:\n",
    "p, r, thresholds = precision_recall_curve(y_val, y_scores)\n",
    "\n",
    "# We calculate the  F1 scores\n",
    "f1_scores = 2*r*p/(r+p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f619e5e6",
   "metadata": {},
   "source": [
    "Let's plot the **decision chart** of our model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2103b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(\"Precision, Recall Scores and F1 scores as a function of the decision threshold\")\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.plot(thresholds, f1_scores[:-1], \"r-\", label=\"F1-score\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xlabel(\"Decision Threshold\")\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "plot_precision_recall_vs_threshold(p, r, thresholds)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7bf695",
   "metadata": {},
   "source": [
    "We can see that the the optimal threshold to achieve the highest F1 score is set at **0.30** with **59% F1-score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc108d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best threshold: ', thresholds[np.argmax(f1_scores)])\n",
    "print('Best F1-Score: ', np.max(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02f7e1d",
   "metadata": {},
   "source": [
    "Let's creat **an animated confusion matrix** where the users get to choose the **threesholds** and we **dislpay the confusion matrix and recall vs precision curve** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6515ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae10d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f47f43f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize = False,\n",
    "                          title = 'Confusion matrix\"',\n",
    "                          cmap = plt.cm.Blues) :\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])) :\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment = 'center',\n",
    "                 color = 'white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def adjusted_classes(y_scores, t):\n",
    "    \"\"\"\n",
    "    This function adjusts class predictions based on the prediction threshold (t).\n",
    "    Will only work for binary classification problems.\n",
    "    \"\"\"\n",
    "    return [1 if y >= t else 0 for y in y_scores]\n",
    "\n",
    "def precision_recall_threshold(p, r, thresholds, t=0.5):\n",
    "    \"\"\"\n",
    "    plots the precision recall curve and shows the current value for each\n",
    "    by identifying the classifier's threshold (t).\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate new class predictions based on the adjusted_classes\n",
    "    # function above and view the resulting confusion matrix.\n",
    "    y_pred_adj = adjusted_classes(y_scores, t)\n",
    "    \n",
    "    cm = confusion_matrix(y_val, y_pred_adj)\n",
    "    class_names = [0,1]\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm, \n",
    "                      classes=class_names, \n",
    "                      title='RF Confusion matrix')\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.title(\"Precision and Recall curve ^ = current threshold\")\n",
    "    plt.step(r, p, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(r, p, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "    \n",
    "    plt.xlabel('Recall');\n",
    "    plt.ylabel('Precision');\n",
    "    \n",
    "    # plot the current threshold on the line\n",
    "    close_default_clf = np.argmin(np.abs(thresholds - t))\n",
    "    plt.plot(r[close_default_clf], p[close_default_clf], '^', c='k',\n",
    "            markersize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f079877",
   "metadata": {},
   "outputs": [],
   "source": [
    "slider = widgets.IntSlider(\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Slider:',\n",
    "    value=3 # The best threshhold for our model\n",
    ")\n",
    "display(slider)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'For this threshold : {slider.value/10}, the confusion matrix is as follow :')\n",
    "precision_recall_threshold(p, r, thresholds, slider.value/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab92561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.title('ROC Curve')\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([-0.005, 1, 0, 1.005])\n",
    "    plt.xticks(np.arange(0,1, 0.05), rotation=90)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5aa9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, auc_thresholds = roc_curve(y_val, y_scores)\n",
    "print(f'AUC : {auc(fpr, tpr)}') # AUC of ROC\n",
    "plot_roc_curve(fpr, tpr, 'recall_optimized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c741c",
   "metadata": {},
   "source": [
    "Now, let's test this model on our **test set** : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc336ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_y,m.predict(test_x_final)) , \\\n",
    "recall_score(test_y,m.predict(test_x_final)) , \\\n",
    "f1_score(test_y,m.predict(test_x_final), average='binary', pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b897e7",
   "metadata": {},
   "source": [
    "# Results : Partial dependency and SHAP values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636344f8",
   "metadata": {},
   "source": [
    "Let's look at **partial dependence plots**. \n",
    "\n",
    "**Partial dependence** plots try to answer the question: if a row varied on nothing other than the feature in question, how would it impact the dependent variable?\n",
    "\n",
    "For instance, how does **capital_gains** and **dividends_from_stocks** impact probability of belonging to the +50k income levl, all other things being equal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f7359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(20, 8))\n",
    "plot_partial_dependence(m, X_val_final, ['capital_gains','dividends_from_stocks'], percentiles=(0,1),\n",
    "                        grid_resolution=15, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d24637",
   "metadata": {},
   "source": [
    "Looking first at the **dividends_from_stocks** plot, we can see a nearly linear relationship between capital dividends_from_stocks and the probabillity of income level.\n",
    "Same for **capital_gains** at 5 standad deviation from the mean after reaching a steady state above that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f678a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cceab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c7bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_show = 20\n",
    "data_for_prediction = test_x_final.iloc[row_to_show]  # use 1 row of data here. Could use multiple rows if desired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea2e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(m)\n",
    "\n",
    "# Calculate Shap values\n",
    "shap_values = explainer.shap_values(data_for_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9cba69",
   "metadata": {},
   "source": [
    "The above explanation shows features each contributing to push the model output from the base value (the average model output over the training dataset we passed) to the model output. Features pushing the prediction higher are shown in red, those pushing the prediction lower are in blue\n",
    "\n",
    "- The base_value here is 0.062 while our predicted value is 0.0.\n",
    "- sex = 1 has the biggest impact on increasing the prediction, while\n",
    "- Weeks_worked_im_year (below the average) and Age (below the average) feature has the biggest effect in decreasing the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(m)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\n",
    "shap_values = explainer.shap_values(test_x_final.iloc[:1000,])\n",
    "\n",
    "# Make plot. Index of [1] is explained in text below.\n",
    "shap.summary_plot(shap_values[1],test_x_final.iloc[:1000,])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea5125",
   "metadata": {},
   "source": [
    "For every dot:\n",
    "\n",
    "- Vertical location shows what feature it is depicting\n",
    "- Color shows whether that feature was high or low for that row of the dataset\n",
    "- Horizontal location shows whether the effect of that value caused a higher or lower prediction.\n",
    "\n",
    "For the **age** variable, the point in the upper left was depicts a person whose age level is less thereby reducing the prediction of income level +50k class by 0.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c0f5c",
   "metadata": {},
   "source": [
    "# Conclusion :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6708b24a",
   "metadata": {},
   "source": [
    "In this work, we presented some techniques for dealing with a machine learning project :\n",
    "\n",
    "- We used Decision Tree ensembles : Random Forest are the easiest to train, because they are extremely resilient to hyperparameter choices and require very little preprocessing. They are very fast to train, and should not overfit if we have enough trees.\n",
    "\n",
    "- we used the model for feature selection and partial dependence analysis and Shap values, to get a better understanding of our data.\n",
    "\n",
    "For futur improvements :\n",
    "- We can try Gradient Boosting machines as in theory are just as fast to train as random forests, but in practice we will have to try lots of different hyperparameters. They can overfit, but they are often a little more accurate than random forests.\n",
    "\n",
    "- We can try OneHotEncoder with PCA to deal with the multiple modalities on our categorical variables.\n",
    "\n",
    "- We can creat new features to challenge the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5811fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288bcc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe51c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46d66a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
